{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required necessary libraries are installed pandas numpai sea Bond matplot live and few others algorithm library algorithms from sk learn our installed\n",
    "The collected data from the Google form is converted into CSV commerce operated values and it is loaded to a data frame and named it named as DF \n",
    "In the initial process of cleaning the data the date and time of collections are dropped and and the most irrelevant column with most and nan values is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             area_of_improvement recommdation_likeliness  \\\n",
      "0              Campus facilities                  Likely   \n",
      "1  Communication and information                  Likely   \n",
      "2       Student support services                 Neutral   \n",
      "3              Campus facilities             Very likely   \n",
      "4       Student support services           Very unlikely   \n",
      "\n",
      "  communication_availability online_platform extracurricular_activities  \\\n",
      "0                    Average         Average                       Good   \n",
      "1                  Excellent       Excellent                       Good   \n",
      "2                    Average         Average                    Average   \n",
      "3                    Average            Good                       Good   \n",
      "4                  Excellent       Excellent                       Poor   \n",
      "\n",
      "  library_availibility prompt_feedback  classroom_interaction  course_clarity  \\\n",
      "0              Average             Yes                      5               4   \n",
      "1            Excellent              No                      4               4   \n",
      "2              Average              No                      3               3   \n",
      "3                 Good             Yes                      5               3   \n",
      "4        Below Average              No                      3               3   \n",
      "\n",
      "  student_support_services     academic_advisers    cleanliness  \\\n",
      "0                       No  Moderately Available  Below Average   \n",
      "1                      Yes  Moderately Available      Excellent   \n",
      "2                       No  Moderately Available        Average   \n",
      "3                      Yes  Moderately Available           Good   \n",
      "4                       No  Moderately Available           Good   \n",
      "\n",
      "  research_resources          accommodation course_curriculum  \\\n",
      "0             Average  Moderately satisfied              Good   \n",
      "1           Excellent        Very satisfied         Excellent   \n",
      "2             Average  Moderately satisfied           Average   \n",
      "3                Good        Very satisfied              Good   \n",
      "4           Excellent         Not satisfied     Below Average   \n",
      "\n",
      "  teaching_quality  student_satisfaction  \n",
      "0             Good                     4  \n",
      "1          Average                     4  \n",
      "2          Average                     3  \n",
      "3          Average                     4  \n",
      "4          Average                     2  \n",
      "Index(['area_of_improvement', 'recommdation_likeliness',\n",
      "       'communication_availability', 'online_platform',\n",
      "       'extracurricular_activities', 'library_availibility', 'prompt_feedback',\n",
      "       'classroom_interaction', 'course_clarity', 'student_support_services',\n",
      "       'academic_advisers', 'cleanliness', 'research_resources ',\n",
      "       'accommodation', 'course_curriculum', 'teaching_quality',\n",
      "       'student_satisfaction'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   area_of_improvement         299 non-null    object\n",
      " 1   recommdation_likeliness     299 non-null    object\n",
      " 2   communication_availability  299 non-null    object\n",
      " 3   online_platform             299 non-null    object\n",
      " 4   extracurricular_activities  299 non-null    object\n",
      " 5   library_availibility        299 non-null    object\n",
      " 6   prompt_feedback             299 non-null    object\n",
      " 7   classroom_interaction       299 non-null    int64 \n",
      " 8   course_clarity              299 non-null    int64 \n",
      " 9   student_support_services    299 non-null    object\n",
      " 10  academic_advisers           299 non-null    object\n",
      " 11  cleanliness                 299 non-null    object\n",
      " 12  research_resources          299 non-null    object\n",
      " 13  accommodation               299 non-null    object\n",
      " 14  course_curriculum           299 non-null    object\n",
      " 15  teaching_quality            299 non-null    object\n",
      " 16  student_satisfaction        299 non-null    int64 \n",
      "dtypes: int64(3), object(14)\n",
      "memory usage: 39.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('vp1.csv',encoding='latin-1')\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean    3.361204\n",
      "50%     3.000000\n",
      "std     1.286207\n",
      "Name: student_satisfaction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#descriptive analysis\n",
    "\n",
    "#  mean, median, and standard deviation for student_satisfaction are calculated\n",
    "descriptive_stats = df['student_satisfaction'].describe()\n",
    "stats_df = descriptive_stats.loc[['mean', '50%', 'std']]\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptive analysis is done after prepressing where based on students satisfaction score given by students mean median and standard deviations are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "\n",
    "#statistics for student_satisfaction are calculated\n",
    "average_rating = df['student_satisfaction'].mean()\n",
    "std_dev = df['student_satisfaction'].std()\n",
    "median_value = df['student_satisfaction'].median()\n",
    "\n",
    "# a bar chart for average rating, standard deviation, and median are created\n",
    "plt.bar(['Average Rating', 'Standard Deviation', 'Median'], [average_rating, std_dev, median_value])\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Statistics for Student Satisfaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the visualization for the same thing is done using a bar chart with multiple bars for average rating standard deviation and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area_of_improvement', 'recommdation_likeliness',\n",
      "       'communication_availability', 'online_platform',\n",
      "       'extracurricular_activities', 'library_availibility', 'prompt_feedback',\n",
      "       'classroom_interaction', 'course_clarity', 'student_support_services',\n",
      "       'academic_advisers', 'cleanliness', 'research_resources ',\n",
      "       'accommodation', 'course_curriculum', 'teaching_quality',\n",
      "       'student_satisfaction'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation analysis done for students satisfaction and two important categories of the collected data course clarity and teaching quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      3\n",
      "1      2\n",
      "2      2\n",
      "3      2\n",
      "4      2\n",
      "      ..\n",
      "294    4\n",
      "295    3\n",
      "296    4\n",
      "297    1\n",
      "298    3\n",
      "Name: teaching_quality, Length: 299, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mapping/encoding\n",
    "df['recommdation_likeliness'] = df['recommdation_likeliness'].map({\n",
    "    'Very unlikely': 0,\n",
    "    'Unlikely': 1,\n",
    "    'Neutral': 2,\n",
    "    'Likely': 3,\n",
    "    'Very likely': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['communication_availability'] = df['communication_availability'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['online_platform'] = df['online_platform'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['library_availibility'] = df['library_availibility'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['prompt_feedback'] = df['prompt_feedback'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "    \n",
    "})\n",
    "\n",
    "df['student_support_services'] = df['student_support_services'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "})\n",
    "\n",
    "df['academic_advisers'] = df['academic_advisers'].map({\n",
    "    'Not Available': 0,\n",
    "    'Slightly Available': 1,\n",
    "    'Moderately Available': 2,\n",
    "    'Very Available': 3\n",
    "   \n",
    "})\n",
    "\n",
    "df['cleanliness'] = df['cleanliness'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['research_resources '] = df['research_resources '].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['accommodation'] = df['accommodation'].map({\n",
    "    'Not satisfied': 0,\n",
    "    'Slightly satisfied': 1,\n",
    "    'Moderately satisfied': 2,\n",
    "    'Very satisfied': 3,\n",
    "    'Extremely satisfied': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['course_curriculum'] = df['course_curriculum'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['teaching_quality'] = df['teaching_quality'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "print(df['teaching_quality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommdation_likeliness</th>\n",
       "      <th>communication_availability</th>\n",
       "      <th>online_platform</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>library_availibility</th>\n",
       "      <th>prompt_feedback</th>\n",
       "      <th>classroom_interaction</th>\n",
       "      <th>course_clarity</th>\n",
       "      <th>student_support_services</th>\n",
       "      <th>academic_advisers</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>research_resources</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>course_curriculum</th>\n",
       "      <th>teaching_quality</th>\n",
       "      <th>student_satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.742475</td>\n",
       "      <td>2.67893</td>\n",
       "      <td>2.712375</td>\n",
       "      <td>2.612040</td>\n",
       "      <td>2.722408</td>\n",
       "      <td>0.729097</td>\n",
       "      <td>3.438127</td>\n",
       "      <td>3.364548</td>\n",
       "      <td>0.525084</td>\n",
       "      <td>1.979933</td>\n",
       "      <td>2.742475</td>\n",
       "      <td>2.752508</td>\n",
       "      <td>2.357860</td>\n",
       "      <td>2.899666</td>\n",
       "      <td>2.963211</td>\n",
       "      <td>3.361204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.088640</td>\n",
       "      <td>1.14572</td>\n",
       "      <td>1.194597</td>\n",
       "      <td>1.278365</td>\n",
       "      <td>1.310720</td>\n",
       "      <td>0.445171</td>\n",
       "      <td>1.302560</td>\n",
       "      <td>1.317492</td>\n",
       "      <td>0.500208</td>\n",
       "      <td>0.982873</td>\n",
       "      <td>1.286443</td>\n",
       "      <td>1.080153</td>\n",
       "      <td>1.232541</td>\n",
       "      <td>0.967578</td>\n",
       "      <td>0.924309</td>\n",
       "      <td>1.286207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recommdation_likeliness  communication_availability  online_platform  \\\n",
       "count               299.000000                   299.00000       299.000000   \n",
       "mean                  2.742475                     2.67893         2.712375   \n",
       "std                   1.088640                     1.14572         1.194597   \n",
       "min                   0.000000                     0.00000         0.000000   \n",
       "25%                   2.000000                     2.00000         2.000000   \n",
       "50%                   3.000000                     3.00000         3.000000   \n",
       "75%                   4.000000                     4.00000         4.000000   \n",
       "max                   4.000000                     4.00000         4.000000   \n",
       "\n",
       "       extracurricular_activities  library_availibility  prompt_feedback  \\\n",
       "count                  299.000000            299.000000       299.000000   \n",
       "mean                     2.612040              2.722408         0.729097   \n",
       "std                      1.278365              1.310720         0.445171   \n",
       "min                      0.000000              0.000000         0.000000   \n",
       "25%                      2.000000              2.000000         0.000000   \n",
       "50%                      3.000000              3.000000         1.000000   \n",
       "75%                      4.000000              4.000000         1.000000   \n",
       "max                      4.000000              4.000000         1.000000   \n",
       "\n",
       "       classroom_interaction  course_clarity  student_support_services  \\\n",
       "count             299.000000      299.000000                299.000000   \n",
       "mean                3.438127        3.364548                  0.525084   \n",
       "std                 1.302560        1.317492                  0.500208   \n",
       "min                 1.000000        1.000000                  0.000000   \n",
       "25%                 3.000000        3.000000                  0.000000   \n",
       "50%                 4.000000        3.000000                  1.000000   \n",
       "75%                 5.000000        4.000000                  1.000000   \n",
       "max                 5.000000        5.000000                  1.000000   \n",
       "\n",
       "       academic_advisers  cleanliness  research_resources   accommodation  \\\n",
       "count         299.000000   299.000000           299.000000     299.000000   \n",
       "mean            1.979933     2.742475             2.752508       2.357860   \n",
       "std             0.982873     1.286443             1.080153       1.232541   \n",
       "min             0.000000     0.000000             0.000000       0.000000   \n",
       "25%             1.000000     2.000000             2.000000       2.000000   \n",
       "50%             2.000000     3.000000             3.000000       2.000000   \n",
       "75%             3.000000     4.000000             3.500000       3.000000   \n",
       "max             3.000000     4.000000             4.000000       4.000000   \n",
       "\n",
       "       course_curriculum  teaching_quality  student_satisfaction  \n",
       "count         299.000000        299.000000            299.000000  \n",
       "mean            2.899666          2.963211              3.361204  \n",
       "std             0.967578          0.924309              1.286207  \n",
       "min             0.000000          0.000000              1.000000  \n",
       "25%             3.000000          3.000000              3.000000  \n",
       "50%             3.000000          3.000000              3.000000  \n",
       "75%             4.000000          4.000000              4.000000  \n",
       "max             4.000000          4.000000              5.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         student_satisfaction  recommdation_likeliness\n",
      "student_satisfaction                 1.000000                 0.447708\n",
      "recommdation_likeliness              0.447708                 1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "attributes = ['student_satisfaction', 'recommdation_likeliness']\n",
    "subset_df = df[attributes]\n",
    "\n",
    "#correlation matrix is created\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "#heatmap visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            student_satisfaction  communication_availability\n",
      "student_satisfaction                    1.000000                    0.443308\n",
      "communication_availability              0.443308                    1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'communication_availability']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  online_platform\n",
      "student_satisfaction              1.000000         0.340842\n",
      "online_platform                   0.340842         1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'online_platform']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            student_satisfaction  extracurricular_activities\n",
      "student_satisfaction                    1.000000                    0.434503\n",
      "extracurricular_activities              0.434503                    1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'extracurricular_activities']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  library_availibility\n",
      "student_satisfaction              1.000000              0.423937\n",
      "library_availibility              0.423937              1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "attributes = ['student_satisfaction', 'library_availibility']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  prompt_feedback\n",
      "student_satisfaction              1.000000         0.271099\n",
      "prompt_feedback                   0.271099         1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','prompt_feedback']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       student_satisfaction  classroom_interaction\n",
      "student_satisfaction               1.000000               0.620285\n",
      "classroom_interaction              0.620285               1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','classroom_interaction']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  course_clarity\n",
      "student_satisfaction              1.000000        0.591366\n",
      "course_clarity                    0.591366        1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','course_clarity']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          student_satisfaction  student_support_services\n",
      "student_satisfaction                  1.000000                  0.178856\n",
      "student_support_services              0.178856                  1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','student_support_services']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  academic_advisers\n",
      "student_satisfaction              1.000000           0.417193\n",
      "academic_advisers                 0.417193           1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','academic_advisers']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  cleanliness\n",
      "student_satisfaction              1.000000     0.421458\n",
      "cleanliness                       0.421458     1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','cleanliness']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  research_resources \n",
      "student_satisfaction              1.000000             0.424455\n",
      "research_resources                0.424455             1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','research_resources ']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  accommodation\n",
      "student_satisfaction              1.000000       0.447379\n",
      "accommodation                     0.447379       1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'accommodation']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  course_curriculum\n",
      "student_satisfaction               1.00000            0.40402\n",
      "course_curriculum                  0.40402            1.00000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction',  'course_curriculum']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  teaching_quality\n",
      "student_satisfaction              1.000000          0.423321\n",
      "teaching_quality                  0.423321          1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'teaching_quality']\n",
    "subset_df = df[attributes]\n",
    "correlation_matrix = subset_df.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot\n",
    "sns.boxplot(x='recommdation_likeliness', y='student_satisfaction', data=df)\n",
    "plt.xlabel('recommdation_likeliness')\n",
    "plt.ylabel('student_satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot \n",
    "sns.boxplot(x='communication_availability', y='student_satisfaction', data=df)\n",
    "plt.xlabel('communication_availability')\n",
    "plt.ylabel('student_satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "# Jittering the data points\n",
    "jitter_x = np.random.uniform(-0.2, 0.2, len(df))\n",
    "jitter_y = np.random.uniform(-0.1, 0.1, len(df))\n",
    "plt.scatter(df['online_platform'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Online Platform')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Online Platform vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Avg', 'Avg', 'Good', 'Excellent'])  # Set custom x-axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot w\n",
    "plt.scatter(df['extracurricular_activities'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('extracurricular_activities')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('extracurricular_activities vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Avg', 'Avg', 'Good', 'Excellent']) \n",
    "plt.show()\n",
    "\n",
    " \n",
    "plt.scatter(df['library_availibility'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('library_availibility')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('library_availibility vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Avg', 'Avg', 'Good', 'Excellent'])  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(df['prompt_feedback'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Prompt Feedback')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Prompt Feedback vs Student Satisfaction')\n",
    "plt.xticks([0, 1], ['No', 'Yes'])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot for 'academic_advisers' against 'student_satisfaction'\n",
    "sns.kdeplot(data=df, x='academic_advisers', hue='student_satisfaction', fill=True)\n",
    "plt.xlabel('Academic Advisers Availability')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot: Academic Advisers Availability vs Student Satisfaction')\n",
    "plt.legend(title='Student Satisfaction', labels=['Not Satisfied', 'Satisfied', 'Neutral', 'Likely'])\n",
    "plt.xticks([0, 1, 2, 3], ['Not Available', 'Slightly Available', 'Moderately Available', 'Very Available'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 5, 2, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['course_clarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot\n",
    "sns.kdeplot(data=df, x='course_clarity', hue='student_satisfaction', fill=True)\n",
    "plt.xlabel('Course Clarity')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot: Course Clarity vs Student Satisfaction')\n",
    "plt.legend(title='Student Satisfaction', labels=['Not Satisfied', 'Satisfied', 'Neutral', 'Likely'])\n",
    "plt.xticks([1, 2, 3, 4, 5], ['Very Unclear', 'Unclear', 'Neutral', 'Clear', 'Very Clear'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 3, 1, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['research_resources '].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot\n",
    "sns.kdeplot(data=df, x='research_resources ', hue='student_satisfaction', fill=True)\n",
    "plt.xlabel('Research Resources Availibility')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot: Research Resources vs Student Satisfaction')\n",
    "plt.legend(title='Student Satisfaction', labels=['Not Satisfied', 'Satisfied', 'Neutral', 'Likely'])\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Not Available  ', 'Slightly ', 'Moderately ', 'Very', 'Extremely'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for 'cleanliness' against 'student_satisfaction'\n",
    "plt.scatter(df['cleanliness'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Cleanliness')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Cleanliness vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for 'research_resources ' against 'student_satisfaction'\n",
    "plt.scatter(df['research_resources '] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Research Resources')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Research Resources vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Scatter plot for 'accommodation' against 'student_satisfaction'----when in confusion what to infer use boxplot\n",
    "plt.scatter(df['accommodation'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Accommodation')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Accommodation vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Not satisfied', 'Slightly satisfied', 'Moderately satisfied', 'Very satisfied', 'Extremely satisfied'])\n",
    "plt.show()\n",
    "\n",
    "# Box plot for 'accommodation' against 'student_satisfaction'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='accommodation', y='student_satisfaction', data=df, palette='Set1')\n",
    "plt.xlabel('Accommodation')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Accommodation vs Student Satisfaction (Box Plot)')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Not satisfied', 'Slightly satisfied', 'Moderately satisfied', 'Very satisfied', 'Extremely satisfied'])\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for 'course_curriculum' against 'student_satisfaction'----when in confusion what to infer use boxplot\n",
    "plt.scatter(df['course_curriculum'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Course Curriculum')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Course Curriculum vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "# Box plot for 'course_curriculum' against 'student_satisfaction'\n",
    "sns.boxplot(data=df, x='course_curriculum', y='student_satisfaction', palette='Set1')\n",
    "plt.xlabel('Course Curriculum')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Course Curriculum vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for 'teaching_quality' against 'student_satisfaction'----when in confusion what to infer use boxplot\n",
    "plt.scatter(df['teaching_quality'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Teaching Quality')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Teaching Quality vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Box plot for 'teaching_quality' against 'student_satisfaction'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='teaching_quality', y='student_satisfaction', data=df, palette='pastel')\n",
    "plt.xlabel('Teaching Quality')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Teaching Quality vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_attributes = ['recommdation_likeliness', 'communication_availability',\n",
    "              'online_platform', 'extracurricular_activities', 'library_availibility',\n",
    "              'prompt_feedback', 'classroom_interaction', 'course_clarity',\n",
    "              'student_support_services', 'academic_advisers', 'cleanliness',\n",
    "              'research_resources ', 'accommodation', 'course_curriculum',\n",
    "              'teaching_quality']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4666666666666667\n",
      "Accuracy: 0.4666666666666667\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 5  1  3  0  0]\n",
      " [ 1  2 14  6  0]\n",
      " [ 2  0  6  4  0]\n",
      " [ 3  1  0  2  7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.67      0.25         3\n",
      "           2       0.25      0.11      0.15         9\n",
      "           3       0.58      0.61      0.60        23\n",
      "           4       0.33      0.33      0.33        12\n",
      "           5       1.00      0.54      0.70        13\n",
      "\n",
      "    accuracy                           0.47        60\n",
      "   macro avg       0.46      0.45      0.41        60\n",
      "weighted avg       0.55      0.47      0.48        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "\n",
    "academic_attributes = ['student_satisfaction','recommdation_likeliness',\n",
    "'course_clarity',\n",
    "'research_resources ',\n",
    "'course_curriculum',\n",
    "'teaching_quality']\n",
    "academic_df = df[academic_attributes]\n",
    "# encoding the categorical variables\n",
    "academic_df_encoded = pd.get_dummies(academic_df, drop_first=True)\n",
    "\n",
    "# data split\n",
    "X = academic_df_encoded.drop('student_satisfaction', axis=1)\n",
    "y = academic_df_encoded['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5166666666666667\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  7  0  0]\n",
      " [ 2  3 12  5  1]\n",
      " [ 0  0  3  7  2]\n",
      " [ 1  0  2  0 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.67      0.40         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.48      0.52      0.50        23\n",
      "           4       0.58      0.58      0.58        12\n",
      "           5       0.77      0.77      0.77        13\n",
      "\n",
      "    accuracy                           0.52        60\n",
      "   macro avg       0.42      0.51      0.45        60\n",
      "weighted avg       0.48      0.52      0.49        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/n5mjk3bs7tjc_2kc5wbk_ft00000gn/T/ipykernel_8432/3785578698.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  support_df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "support_attributes = ['prompt_feedback',\n",
    "'classroom_interaction',\n",
    "'student_support_services',\n",
    "'academic_advisers',\n",
    "'student_satisfaction']\n",
    "support_df = df[support_attributes]\n",
    "\n",
    "# missing values are dropped\n",
    "support_df.dropna(inplace=True)\n",
    "X = support_df.drop('student_satisfaction', axis=1)\n",
    "y = support_df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48333333333333334\n",
      "Confusion Matrix:\n",
      "[[1 0 1 0 1]\n",
      " [1 3 5 0 0]\n",
      " [1 6 9 2 5]\n",
      " [2 0 3 7 0]\n",
      " [0 1 0 3 9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.33      0.25         3\n",
      "           2       0.30      0.33      0.32         9\n",
      "           3       0.50      0.39      0.44        23\n",
      "           4       0.58      0.58      0.58        12\n",
      "           5       0.60      0.69      0.64        13\n",
      "\n",
      "    accuracy                           0.48        60\n",
      "   macro avg       0.44      0.47      0.45        60\n",
      "weighted avg       0.49      0.48      0.48        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/n5mjk3bs7tjc_2kc5wbk_ft00000gn/T/ipykernel_8432/740540724.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  facilty_df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "facilty_attributes = ['student_satisfaction',\n",
    "'communication_availability',\n",
    "'online_platform',\n",
    "'extracurricular_activities',\n",
    "'library_availibility',\n",
    "'accommodation',\n",
    "'cleanliness']\n",
    "\n",
    "facilty_df = df[facilty_attributes]\n",
    "facilty_df.dropna(inplace=True)\n",
    "X = facilty_df.drop('student_satisfaction', axis=1)\n",
    "y =facilty_df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 1  2  6  0  0]\n",
      " [ 4  2 15  0  2]\n",
      " [ 0  2  1  6  3]\n",
      " [ 0  0  0  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.33      0.22      0.27         9\n",
      "           3       0.68      0.65      0.67        23\n",
      "           4       1.00      0.50      0.67        12\n",
      "           5       0.72      1.00      0.84        13\n",
      "\n",
      "    accuracy                           0.65        60\n",
      "   macro avg       0.62      0.67      0.60        60\n",
      "weighted avg       0.69      0.65      0.64        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree with feature eng- cat1-equal weights\n",
    "academic_attributes = ['student_satisfaction','recommdation_likeliness','course_clarity','research_resources ','course_curriculum','prompt_feedback','teaching_quality']\n",
    "df['academic_interaction'] = df[academic_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 1\n",
    "weights_category1 = [0.1,0.1, 0.1, 0.1, 0.1, 0.1,0.1]  \n",
    "df['academic_weighted_score'] = (df[academic_attributes] * weights_category1).sum(axis=1)\n",
    "X = df[['academic_weighted_score','academic_interaction']]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6166666666666667\n",
      "Confusion Matrix:\n",
      "[[ 2  1  0  0  0]\n",
      " [ 0  5  3  1  0]\n",
      " [ 1  3 12  6  1]\n",
      " [ 1  0  2  7  2]\n",
      " [ 0  0  2  0 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.67      0.57         3\n",
      "           2       0.56      0.56      0.56         9\n",
      "           3       0.63      0.52      0.57        23\n",
      "           4       0.50      0.58      0.54        12\n",
      "           5       0.79      0.85      0.81        13\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.59      0.63      0.61        60\n",
      "weighted avg       0.62      0.62      0.62        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree with feature eng- cat1-chosen weights\n",
    "academic_attributes = ['student_satisfaction','recommdation_likeliness','course_clarity','research_resources ','course_curriculum','prompt_feedback','teaching_quality']\n",
    "\n",
    "df['academic_interaction'] = df[academic_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 1\n",
    "weights_category1 = [0.1, 0.1, 0.4, 0.2, 0.2,0.1,0.4] \n",
    "df['academic_weighted_score'] = (df[academic_attributes] * weights_category1).sum(axis=1)\n",
    "X = df[['academic_weighted_score','academic_interaction']]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommdation_likeliness</th>\n",
       "      <th>communication_availability</th>\n",
       "      <th>online_platform</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>library_availibility</th>\n",
       "      <th>prompt_feedback</th>\n",
       "      <th>classroom_interaction</th>\n",
       "      <th>course_clarity</th>\n",
       "      <th>student_support_services</th>\n",
       "      <th>academic_advisers</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>research_resources</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>course_curriculum</th>\n",
       "      <th>teaching_quality</th>\n",
       "      <th>student_satisfaction</th>\n",
       "      <th>academic_interaction</th>\n",
       "      <th>academic_weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.742475</td>\n",
       "      <td>2.67893</td>\n",
       "      <td>2.712375</td>\n",
       "      <td>2.612040</td>\n",
       "      <td>2.722408</td>\n",
       "      <td>0.729097</td>\n",
       "      <td>3.438127</td>\n",
       "      <td>3.364548</td>\n",
       "      <td>0.525084</td>\n",
       "      <td>1.979933</td>\n",
       "      <td>2.742475</td>\n",
       "      <td>2.752508</td>\n",
       "      <td>2.357860</td>\n",
       "      <td>2.899666</td>\n",
       "      <td>2.963211</td>\n",
       "      <td>3.361204</td>\n",
       "      <td>1276.247492</td>\n",
       "      <td>4.069565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.088640</td>\n",
       "      <td>1.14572</td>\n",
       "      <td>1.194597</td>\n",
       "      <td>1.278365</td>\n",
       "      <td>1.310720</td>\n",
       "      <td>0.445171</td>\n",
       "      <td>1.302560</td>\n",
       "      <td>1.317492</td>\n",
       "      <td>0.500208</td>\n",
       "      <td>0.982873</td>\n",
       "      <td>1.286443</td>\n",
       "      <td>1.080153</td>\n",
       "      <td>1.232541</td>\n",
       "      <td>0.967578</td>\n",
       "      <td>0.924309</td>\n",
       "      <td>1.286207</td>\n",
       "      <td>1870.506890</td>\n",
       "      <td>1.116702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recommdation_likeliness  communication_availability  online_platform  \\\n",
       "count               299.000000                   299.00000       299.000000   \n",
       "mean                  2.742475                     2.67893         2.712375   \n",
       "std                   1.088640                     1.14572         1.194597   \n",
       "min                   0.000000                     0.00000         0.000000   \n",
       "25%                   2.000000                     2.00000         2.000000   \n",
       "50%                   3.000000                     3.00000         3.000000   \n",
       "75%                   4.000000                     4.00000         4.000000   \n",
       "max                   4.000000                     4.00000         4.000000   \n",
       "\n",
       "       extracurricular_activities  library_availibility  prompt_feedback  \\\n",
       "count                  299.000000            299.000000       299.000000   \n",
       "mean                     2.612040              2.722408         0.729097   \n",
       "std                      1.278365              1.310720         0.445171   \n",
       "min                      0.000000              0.000000         0.000000   \n",
       "25%                      2.000000              2.000000         0.000000   \n",
       "50%                      3.000000              3.000000         1.000000   \n",
       "75%                      4.000000              4.000000         1.000000   \n",
       "max                      4.000000              4.000000         1.000000   \n",
       "\n",
       "       classroom_interaction  course_clarity  student_support_services  \\\n",
       "count             299.000000      299.000000                299.000000   \n",
       "mean                3.438127        3.364548                  0.525084   \n",
       "std                 1.302560        1.317492                  0.500208   \n",
       "min                 1.000000        1.000000                  0.000000   \n",
       "25%                 3.000000        3.000000                  0.000000   \n",
       "50%                 4.000000        3.000000                  1.000000   \n",
       "75%                 5.000000        4.000000                  1.000000   \n",
       "max                 5.000000        5.000000                  1.000000   \n",
       "\n",
       "       academic_advisers  cleanliness  research_resources   accommodation  \\\n",
       "count         299.000000   299.000000           299.000000     299.000000   \n",
       "mean            1.979933     2.742475             2.752508       2.357860   \n",
       "std             0.982873     1.286443             1.080153       1.232541   \n",
       "min             0.000000     0.000000             0.000000       0.000000   \n",
       "25%             1.000000     2.000000             2.000000       2.000000   \n",
       "50%             2.000000     3.000000             3.000000       2.000000   \n",
       "75%             3.000000     4.000000             3.500000       3.000000   \n",
       "max             3.000000     4.000000             4.000000       4.000000   \n",
       "\n",
       "       course_curriculum  teaching_quality  student_satisfaction  \\\n",
       "count         299.000000        299.000000            299.000000   \n",
       "mean            2.899666          2.963211              3.361204   \n",
       "std             0.967578          0.924309              1.286207   \n",
       "min             0.000000          0.000000              1.000000   \n",
       "25%             3.000000          3.000000              3.000000   \n",
       "50%             3.000000          3.000000              3.000000   \n",
       "75%             4.000000          4.000000              4.000000   \n",
       "max             4.000000          4.000000              5.000000   \n",
       "\n",
       "       academic_interaction  academic_weighted_score  \n",
       "count            299.000000               299.000000  \n",
       "mean            1276.247492                 4.069565  \n",
       "std             1870.506890                 1.116702  \n",
       "min                0.000000                 0.500000  \n",
       "25%                0.000000                 3.400000  \n",
       "50%              486.000000                 4.100000  \n",
       "75%             1674.000000                 4.900000  \n",
       "max             6400.000000                 5.800000  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 2  0 17  2  2]\n",
      " [ 0  0  3  7  2]\n",
      " [ 1  0  2  0 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.67      0.44         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.55      0.74      0.63        23\n",
      "           4       0.78      0.58      0.67        12\n",
      "           5       0.71      0.77      0.74        13\n",
      "\n",
      "    accuracy                           0.60        60\n",
      "   macro avg       0.47      0.55      0.50        60\n",
      "weighted avg       0.54      0.60      0.56        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#decision tree with feature eng- cat2- assigned weights\n",
    "\n",
    "support_attributes = ['prompt_feedback', 'classroom_interaction', 'student_support_services', 'academic_advisers']\n",
    "\n",
    "\n",
    "# Interaction for Category 2\n",
    "df['support_interaction'] = df[support_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 2\n",
    "weights_category2 = [0.1, 0.4, 0.3, 0.1]  \n",
    "df['support_weighted_score'] = (df[support_attributes] * weights_category2).sum(axis=1)\n",
    "X = df[['support_interaction','support_weighted_score']]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5166666666666667\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 0  0  6  3  0]\n",
      " [ 2  0 14  6  1]\n",
      " [ 0  0  2  9  1]\n",
      " [ 0  0  1  5  7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.33      0.33         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.56      0.61      0.58        23\n",
      "           4       0.39      0.75      0.51        12\n",
      "           5       0.78      0.54      0.64        13\n",
      "\n",
      "    accuracy                           0.52        60\n",
      "   macro avg       0.41      0.45      0.41        60\n",
      "weighted avg       0.48      0.52      0.48        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#decision tree with feature eng- cat2-equal weights\n",
    "support_attributes = ['prompt_feedback', 'classroom_interaction', 'student_support_services', 'academic_advisers']\n",
    "\n",
    "# Interaction for Category 2\n",
    "df['support_interaction'] = df[support_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 2\n",
    "weights_category2 = [0.1, 0.1, 0.1, 0.1]  \n",
    "df['support_weighted_score'] = (df[support_attributes] * weights_category2).sum(axis=1)\n",
    "X = df[['support_weighted_score','support_weighted_score']]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 1  0  2  4  2]\n",
      " [ 2  2 14  4  1]\n",
      " [ 1  0  4  3  4]\n",
      " [ 0  0  1  3  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.33      0.25         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.61      0.61      0.61        23\n",
      "           4       0.21      0.25      0.23        12\n",
      "           5       0.56      0.69      0.62        13\n",
      "\n",
      "    accuracy                           0.45        60\n",
      "   macro avg       0.32      0.38      0.34        60\n",
      "weighted avg       0.41      0.45      0.43        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree with feature eng- cat3-equal weights\n",
    "facility_attributes = ['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']\n",
    "\n",
    "# Interaction for Category 3\n",
    "df['facility_interaction'] = df[facility_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 3\n",
    "weights_category3 = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]  \n",
    "df['facility_weighted_score'] = (df[facility_attributes] * weights_category3).sum(axis=1)\n",
    "X = df[['facility_interaction','facility_weighted_score']]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommdation_likeliness</th>\n",
       "      <th>communication_availability</th>\n",
       "      <th>online_platform</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>library_availibility</th>\n",
       "      <th>prompt_feedback</th>\n",
       "      <th>classroom_interaction</th>\n",
       "      <th>course_clarity</th>\n",
       "      <th>student_support_services</th>\n",
       "      <th>academic_advisers</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>research_resources</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>course_curriculum</th>\n",
       "      <th>teaching_quality</th>\n",
       "      <th>student_satisfaction</th>\n",
       "      <th>academic_interaction</th>\n",
       "      <th>academic_weighted_score</th>\n",
       "      <th>support_interaction</th>\n",
       "      <th>support_weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.742475</td>\n",
       "      <td>2.67893</td>\n",
       "      <td>2.712375</td>\n",
       "      <td>2.612040</td>\n",
       "      <td>2.722408</td>\n",
       "      <td>0.729097</td>\n",
       "      <td>3.438127</td>\n",
       "      <td>3.364548</td>\n",
       "      <td>0.525084</td>\n",
       "      <td>1.979933</td>\n",
       "      <td>2.742475</td>\n",
       "      <td>2.752508</td>\n",
       "      <td>2.357860</td>\n",
       "      <td>2.899666</td>\n",
       "      <td>2.963211</td>\n",
       "      <td>3.361204</td>\n",
       "      <td>1276.247492</td>\n",
       "      <td>4.069565</td>\n",
       "      <td>4.277592</td>\n",
       "      <td>1.803679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.088640</td>\n",
       "      <td>1.14572</td>\n",
       "      <td>1.194597</td>\n",
       "      <td>1.278365</td>\n",
       "      <td>1.310720</td>\n",
       "      <td>0.445171</td>\n",
       "      <td>1.302560</td>\n",
       "      <td>1.317492</td>\n",
       "      <td>0.500208</td>\n",
       "      <td>0.982873</td>\n",
       "      <td>1.286443</td>\n",
       "      <td>1.080153</td>\n",
       "      <td>1.232541</td>\n",
       "      <td>0.967578</td>\n",
       "      <td>0.924309</td>\n",
       "      <td>1.286207</td>\n",
       "      <td>1870.506890</td>\n",
       "      <td>1.116702</td>\n",
       "      <td>5.679930</td>\n",
       "      <td>0.626447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recommdation_likeliness  communication_availability  online_platform  \\\n",
       "count               299.000000                   299.00000       299.000000   \n",
       "mean                  2.742475                     2.67893         2.712375   \n",
       "std                   1.088640                     1.14572         1.194597   \n",
       "min                   0.000000                     0.00000         0.000000   \n",
       "25%                   2.000000                     2.00000         2.000000   \n",
       "50%                   3.000000                     3.00000         3.000000   \n",
       "75%                   4.000000                     4.00000         4.000000   \n",
       "max                   4.000000                     4.00000         4.000000   \n",
       "\n",
       "       extracurricular_activities  library_availibility  prompt_feedback  \\\n",
       "count                  299.000000            299.000000       299.000000   \n",
       "mean                     2.612040              2.722408         0.729097   \n",
       "std                      1.278365              1.310720         0.445171   \n",
       "min                      0.000000              0.000000         0.000000   \n",
       "25%                      2.000000              2.000000         0.000000   \n",
       "50%                      3.000000              3.000000         1.000000   \n",
       "75%                      4.000000              4.000000         1.000000   \n",
       "max                      4.000000              4.000000         1.000000   \n",
       "\n",
       "       classroom_interaction  course_clarity  student_support_services  \\\n",
       "count             299.000000      299.000000                299.000000   \n",
       "mean                3.438127        3.364548                  0.525084   \n",
       "std                 1.302560        1.317492                  0.500208   \n",
       "min                 1.000000        1.000000                  0.000000   \n",
       "25%                 3.000000        3.000000                  0.000000   \n",
       "50%                 4.000000        3.000000                  1.000000   \n",
       "75%                 5.000000        4.000000                  1.000000   \n",
       "max                 5.000000        5.000000                  1.000000   \n",
       "\n",
       "       academic_advisers  cleanliness  research_resources   accommodation  \\\n",
       "count         299.000000   299.000000           299.000000     299.000000   \n",
       "mean            1.979933     2.742475             2.752508       2.357860   \n",
       "std             0.982873     1.286443             1.080153       1.232541   \n",
       "min             0.000000     0.000000             0.000000       0.000000   \n",
       "25%             1.000000     2.000000             2.000000       2.000000   \n",
       "50%             2.000000     3.000000             3.000000       2.000000   \n",
       "75%             3.000000     4.000000             3.500000       3.000000   \n",
       "max             3.000000     4.000000             4.000000       4.000000   \n",
       "\n",
       "       course_curriculum  teaching_quality  student_satisfaction  \\\n",
       "count         299.000000        299.000000            299.000000   \n",
       "mean            2.899666          2.963211              3.361204   \n",
       "std             0.967578          0.924309              1.286207   \n",
       "min             0.000000          0.000000              1.000000   \n",
       "25%             3.000000          3.000000              3.000000   \n",
       "50%             3.000000          3.000000              3.000000   \n",
       "75%             4.000000          4.000000              4.000000   \n",
       "max             4.000000          4.000000              5.000000   \n",
       "\n",
       "       academic_interaction  academic_weighted_score  support_interaction  \\\n",
       "count            299.000000               299.000000           299.000000   \n",
       "mean            1276.247492                 4.069565             4.277592   \n",
       "std             1870.506890                 1.116702             5.679930   \n",
       "min                0.000000                 0.500000             0.000000   \n",
       "25%                0.000000                 3.400000             0.000000   \n",
       "50%              486.000000                 4.100000             0.000000   \n",
       "75%             1674.000000                 4.900000             8.000000   \n",
       "max             6400.000000                 5.800000            15.000000   \n",
       "\n",
       "       support_weighted_score  \n",
       "count              299.000000  \n",
       "mean                 1.803679  \n",
       "std                  0.626447  \n",
       "min                  0.400000  \n",
       "25%                  1.300000  \n",
       "50%                  1.800000  \n",
       "75%                  2.300000  \n",
       "max                  2.700000  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 1  2  1  4  1]\n",
      " [ 3  1 13  2  4]\n",
      " [ 3  0  6  3  0]\n",
      " [ 3  0  0  2  8]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.33      0.14         3\n",
      "           2       0.67      0.22      0.33         9\n",
      "           3       0.59      0.57      0.58        23\n",
      "           4       0.27      0.25      0.26        12\n",
      "           5       0.62      0.62      0.62        13\n",
      "\n",
      "    accuracy                           0.45        60\n",
      "   macro avg       0.45      0.40      0.39        60\n",
      "weighted avg       0.52      0.45      0.46        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree with feature eng- cat3-assigned weights\n",
    "facility_attributes = ['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']\n",
    "\n",
    "# Interaction for Category 3\n",
    "df['facility_interaction'] = df[facility_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 3\n",
    "weights_category3 = [0.1, 0.2, 0.2, 0.3, 0.3, 0.1] \n",
    "df['facility_weighted_score'] = (df[facility_attributes] * weights_category3).sum(axis=1)\n",
    "X = df[['facility_weighted_score','facility_interaction']]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area_of_improvement', 'recommdation_likeliness',\n",
      "       'communication_availability', 'online_platform',\n",
      "       'extracurricular_activities', 'library_availibility', 'prompt_feedback',\n",
      "       'classroom_interaction', 'course_clarity', 'student_support_services',\n",
      "       'academic_advisers', 'cleanliness', 'research_resources ',\n",
      "       'accommodation', 'course_curriculum', 'teaching_quality',\n",
      "       'student_satisfaction', 'academic_interaction',\n",
      "       'academic_weighted_score', 'support_interaction',\n",
      "       'support_weighted_score', 'facility_interaction',\n",
      "       'facility_weighted_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df['academic_interaction'] = df[academic_attributes].prod(axis=1)\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6846666666666665\n"
     ]
    }
   ],
   "source": [
    "#KNN-----exp2\n",
    "\n",
    "X = df[['extracurricular_activities','library_availibility','student_support_services','accommodation','cleanliness','online_platform']]  \n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so far the lowest when online and extra things were given more importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.602\n"
     ]
    }
   ],
   "source": [
    "#KNN---exp1\n",
    "# Assuming X contains the features and y contains the 'student_satisfaction'\n",
    "X = df[['academic_interaction',\n",
    "       'academic_weighted_score', 'support_interaction',\n",
    "       'support_weighted_score', 'facility_interaction',\n",
    "       'facility_weighted_score']]  \n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6213333333333332\n"
     ]
    }
   ],
   "source": [
    "#KNN--exp3\n",
    "X = df[['teaching_quality','online_platform','research_resources ',\n",
    "    'course_curriculum','academic_advisers','library_availibility',\n",
    "    'extracurricular_activities','student_support_services']]  \n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of lowest when they studied online,took councelling,extra curricular and studied themselves?m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df.drop(df.columns[17:24], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   area_of_improvement         299 non-null    object\n",
      " 1   recommdation_likeliness     299 non-null    int64 \n",
      " 2   communication_availability  299 non-null    int64 \n",
      " 3   online_platform             299 non-null    int64 \n",
      " 4   extracurricular_activities  299 non-null    int64 \n",
      " 5   library_availibility        299 non-null    int64 \n",
      " 6   prompt_feedback             299 non-null    int64 \n",
      " 7   classroom_interaction       299 non-null    int64 \n",
      " 8   course_clarity              299 non-null    int64 \n",
      " 9   student_support_services    299 non-null    int64 \n",
      " 10  academic_advisers           299 non-null    int64 \n",
      " 11  cleanliness                 299 non-null    int64 \n",
      " 12  research_resources          299 non-null    int64 \n",
      " 13  accommodation               299 non-null    int64 \n",
      " 14  course_curriculum           299 non-null    int64 \n",
      " 15  teaching_quality            299 non-null    int64 \n",
      " 16  student_satisfaction        299 non-null    int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 39.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38333333333333336\n",
      "Confusion Matrix:\n",
      "[[ 0  0  3  0  0]\n",
      " [ 0  0  7  2  0]\n",
      " [ 0  0 20  3  0]\n",
      " [ 0  0  9  3  0]\n",
      " [ 1  0  8  4  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.43      0.87      0.57        23\n",
      "           4       0.25      0.25      0.25        12\n",
      "           5       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.38        60\n",
      "   macro avg       0.14      0.22      0.16        60\n",
      "weighted avg       0.21      0.38      0.27        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB-e1,1\n",
    "academic_attributes = ['recommdation_likeliness', 'course_clarity', 'research_resources ', 'course_curriculum', 'teaching_quality']\n",
    "X = academic_df_encoded.drop('student_satisfaction', axis=1)\n",
    "y = academic_df_encoded['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5666666666666667\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  7  0  0]\n",
      " [ 2  0 16  3  2]\n",
      " [ 0  0  3  6  3]\n",
      " [ 1  0  1  1 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.67      0.40         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.57      0.70      0.63        23\n",
      "           4       0.60      0.50      0.55        12\n",
      "           5       0.67      0.77      0.71        13\n",
      "\n",
      "    accuracy                           0.57        60\n",
      "   macro avg       0.42      0.53      0.46        60\n",
      "weighted avg       0.50      0.57      0.52        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB GAUSS-e1,2\n",
    "\n",
    "academic_attributes = ['recommdation_likeliness', 'course_clarity', 'research_resources ', 'course_curriculum', 'teaching_quality']\n",
    "X = academic_df_encoded.drop('student_satisfaction', axis=1)\n",
    "y = academic_df_encoded['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3\n",
      "Confusion Matrix:\n",
      "[[ 0  0  2  0  1]\n",
      " [ 0  0  5  3  1]\n",
      " [ 0  0 14  7  2]\n",
      " [ 0  0  9  3  0]\n",
      " [ 0  0 12  0  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.33      0.61      0.43        23\n",
      "           4       0.23      0.25      0.24        12\n",
      "           5       0.20      0.08      0.11        13\n",
      "\n",
      "    accuracy                           0.30        60\n",
      "   macro avg       0.15      0.19      0.16        60\n",
      "weighted avg       0.22      0.30      0.24        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB-e3,1\n",
    "facility_attributes = ['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']\n",
    "\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5166666666666667\n",
      "Confusion Matrix:\n",
      "[[ 1  1  0  1  0]\n",
      " [ 1  0  4  1  3]\n",
      " [ 0  2 12  6  3]\n",
      " [ 0  0  3  5  4]\n",
      " [ 0  0  0  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.33      0.40         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.63      0.52      0.57        23\n",
      "           4       0.38      0.42      0.40        12\n",
      "           5       0.57      1.00      0.72        13\n",
      "\n",
      "    accuracy                           0.52        60\n",
      "   macro avg       0.42      0.45      0.42        60\n",
      "weighted avg       0.47      0.52      0.48        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NB-e3,2\n",
    "facility_attributes = ['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 0  0 23  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 1  0 12  0  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.33      0.33         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.40      1.00      0.57        23\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.40        60\n",
      "   macro avg       0.15      0.27      0.18        60\n",
      "weighted avg       0.17      0.40      0.24        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB-support attributes-e2,1\n",
    "\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  4  1  2]\n",
      " [ 4  0 12  5  2]\n",
      " [ 0  0  2  6  4]\n",
      " [ 1  0  2  0 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.67      0.33         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.57      0.52      0.55        23\n",
      "           4       0.50      0.50      0.50        12\n",
      "           5       0.56      0.77      0.65        13\n",
      "\n",
      "    accuracy                           0.50        60\n",
      "   macro avg       0.37      0.49      0.40        60\n",
      "weighted avg       0.45      0.50      0.47        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB-support attributes-e2,2\n",
    "\n",
    "\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 5  1  3  0  0]\n",
      " [ 1  2 14  6  0]\n",
      " [ 1  0  4  7  0]\n",
      " [ 3  1  0  1  8]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      1.00      0.38         3\n",
      "           2       0.25      0.11      0.15         9\n",
      "           3       0.67      0.61      0.64        23\n",
      "           4       0.50      0.58      0.54        12\n",
      "           5       1.00      0.62      0.76        13\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.53      0.58      0.49        60\n",
      "weighted avg       0.62      0.55      0.56        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST-e1\n",
    "\n",
    "\n",
    "academic_attributes = ['recommdation_likeliness', 'course_clarity', 'research_resources ', 'course_curriculum', 'teaching_quality']\n",
    "X = academic_df_encoded.drop('student_satisfaction', axis=1)\n",
    "y = academic_df_encoded['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 1  3 13  5  1]\n",
      " [ 0  0  2  8  2]\n",
      " [ 1  0  0  2 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.67      0.50         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.54      0.57      0.55        23\n",
      "           4       0.53      0.67      0.59        12\n",
      "           5       0.77      0.77      0.77        13\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.45      0.53      0.48        60\n",
      "weighted avg       0.50      0.55      0.52        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST-e2\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Confusion Matrix:\n",
      "[[ 1  1  1  0  0]\n",
      " [ 2  2  5  0  0]\n",
      " [ 0  1 13  5  4]\n",
      " [ 2  0  7  2  1]\n",
      " [ 0  0  0  4  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.33      0.25         3\n",
      "           2       0.50      0.22      0.31         9\n",
      "           3       0.50      0.57      0.53        23\n",
      "           4       0.18      0.17      0.17        12\n",
      "           5       0.64      0.69      0.67        13\n",
      "\n",
      "    accuracy                           0.45        60\n",
      "   macro avg       0.40      0.40      0.39        60\n",
      "weighted avg       0.45      0.45      0.44        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST-e3\n",
    "\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6833333333333333\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 2  0  7  0  0]\n",
      " [ 0  0 20  2  1]\n",
      " [ 1  0  3  8  0]\n",
      " [ 3  0  0  0 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      1.00      0.50         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.67      0.87      0.75        23\n",
      "           4       0.80      0.67      0.73        12\n",
      "           5       0.91      0.77      0.83        13\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.54      0.66      0.56        60\n",
      "weighted avg       0.63      0.68      0.64        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST-e4\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "highest of all models-random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6166666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      1.00      0.43         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.74      0.87      0.80        23\n",
      "           4       0.62      0.42      0.50        12\n",
      "           5       0.64      0.69      0.67        13\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.46      0.60      0.48        60\n",
      "weighted avg       0.56      0.62      0.57        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 5  0  3  1  0]\n",
      " [ 0  0 20  1  2]\n",
      " [ 1  0  3  5  3]\n",
      " [ 2  0  1  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#LOGREG-e1\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "logreg_classifier = LogisticRegression()\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.67      0.36         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.59      0.70      0.64        23\n",
      "           4       0.57      0.33      0.42        12\n",
      "           5       0.56      0.77      0.65        13\n",
      "\n",
      "    accuracy                           0.53        60\n",
      "   macro avg       0.39      0.49      0.41        60\n",
      "weighted avg       0.47      0.53      0.49        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  5  2  0]\n",
      " [ 3  0 16  1  3]\n",
      " [ 0  0  3  4  5]\n",
      " [ 1  0  2  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#LOGREG-e2\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "logreg_classifier = LogisticRegression()\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43333333333333335\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.56      0.43      0.49        23\n",
      "           4       0.28      0.42      0.33        12\n",
      "           5       0.58      0.85      0.69        13\n",
      "\n",
      "    accuracy                           0.43        60\n",
      "   macro avg       0.28      0.34      0.30        60\n",
      "weighted avg       0.39      0.43      0.40        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1  1  0]\n",
      " [ 1  0  4  2  2]\n",
      " [ 2  1 10  8  2]\n",
      " [ 0  0  3  5  4]\n",
      " [ 0  0  0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#LOGREG-e3\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "logreg_classifier = LogisticRegression()\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48333333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.67      0.27         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.57      0.52      0.55        23\n",
      "           4       0.55      0.50      0.52        12\n",
      "           5       0.64      0.69      0.67        13\n",
      "\n",
      "    accuracy                           0.48        60\n",
      "   macro avg       0.39      0.48      0.40        60\n",
      "weighted avg       0.48      0.48      0.47        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 4  0  4  1  0]\n",
      " [ 4  2 12  3  2]\n",
      " [ 1  0  2  6  3]\n",
      " [ 1  0  2  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/n5mjk3bs7tjc_2kc5wbk_ft00000gn/T/ipykernel_8432/703141520.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['student_support_services'] = X['student_support_services'].map({\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#LOGREG-e4\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Map categorical attributes to numerical representations\n",
    "X['student_support_services'] = X['student_support_services'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "})\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X = imputer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "logreg_classifier = LogisticRegression()\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second highest of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      1.00      0.35         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.90      0.78      0.84        23\n",
      "           4       0.60      0.75      0.67        12\n",
      "           5       0.73      0.62      0.67        13\n",
      "\n",
      "    accuracy                           0.63        60\n",
      "   macro avg       0.49      0.63      0.50        60\n",
      "weighted avg       0.63      0.63      0.62        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 7  0  1  1  0]\n",
      " [ 0  0 18  3  2]\n",
      " [ 1  0  1  9  1]\n",
      " [ 3  0  0  2  8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-LINEAR-e1,1\n",
    "\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.67      0.36         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.64      0.78      0.71        23\n",
      "           4       0.50      0.50      0.50        12\n",
      "           5       0.75      0.69      0.72        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.43      0.53      0.46        60\n",
      "weighted avg       0.52      0.58      0.54        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  6  1  0]\n",
      " [ 1  0 18  4  0]\n",
      " [ 1  0  2  6  3]\n",
      " [ 2  0  1  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-RBF-e1,2\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.13      0.67      0.22         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.68      0.65      0.67        23\n",
      "           4       0.54      0.58      0.56        12\n",
      "           5       0.90      0.69      0.78        13\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.45      0.52      0.45        60\n",
      "weighted avg       0.57      0.55      0.55        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 7  0  2  0  0]\n",
      " [ 2  0 15  6  0]\n",
      " [ 1  0  3  7  1]\n",
      " [ 3  0  1  0  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-POLY-e1,3\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48333333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.13      0.67      0.22         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.65      0.57      0.60        23\n",
      "           4       0.57      0.33      0.42        12\n",
      "           5       0.56      0.77      0.65        13\n",
      "\n",
      "    accuracy                           0.48        60\n",
      "   macro avg       0.38      0.47      0.38        60\n",
      "weighted avg       0.49      0.48      0.47        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 3  0  4  2  0]\n",
      " [ 6  0 13  1  3]\n",
      " [ 1  0  2  4  5]\n",
      " [ 3  0  0  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-LINEAR-e2,1\n",
    "\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.67      0.50         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.55      0.74      0.63        23\n",
      "           4       0.67      0.50      0.57        12\n",
      "           5       0.67      0.77      0.71        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.46      0.54      0.48        60\n",
      "weighted avg       0.51      0.58      0.54        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 1  0 17  3  2]\n",
      " [ 0  0  3  6  3]\n",
      " [ 1  0  2  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-RBF-e2,2\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.33      0.33         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.56      0.83      0.67        23\n",
      "           4       0.71      0.42      0.53        12\n",
      "           5       0.62      0.77      0.69        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.45      0.47      0.44        60\n",
      "weighted avg       0.51      0.58      0.53        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 0  0 19  2  2]\n",
      " [ 0  0  3  5  4]\n",
      " [ 1  0  2  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-POLY-e2,3\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.58      0.61      0.60        23\n",
      "           4       0.37      0.58      0.45        12\n",
      "           5       0.65      0.85      0.73        13\n",
      "\n",
      "    accuracy                           0.53        60\n",
      "   macro avg       0.32      0.41      0.36        60\n",
      "weighted avg       0.44      0.53      0.48        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  2  1  0]\n",
      " [ 0  0  5  2  2]\n",
      " [ 0  0 14  7  2]\n",
      " [ 0  0  3  7  2]\n",
      " [ 0  0  0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-LINEAR-e3,1\n",
    "\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF-MORE ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.33      0.40         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.63      0.74      0.68        23\n",
      "           4       0.38      0.50      0.43        12\n",
      "           5       0.73      0.85      0.79        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.45      0.48      0.46        60\n",
      "weighted avg       0.50      0.58      0.54        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  0  1  1  0]\n",
      " [ 1  0  5  2  1]\n",
      " [ 0  0 17  5  1]\n",
      " [ 0  0  4  6  2]\n",
      " [ 0  0  0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-RBF-e3,2\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.59      0.70      0.64        23\n",
      "           4       0.28      0.42      0.33        12\n",
      "           5       0.75      0.69      0.72        13\n",
      "\n",
      "    accuracy                           0.50        60\n",
      "   macro avg       0.32      0.36      0.34        60\n",
      "weighted avg       0.45      0.50      0.47        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  2  0]\n",
      " [ 0  0  5  4  0]\n",
      " [ 2  0 16  4  1]\n",
      " [ 0  0  5  5  2]\n",
      " [ 1  0  0  3  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-POLY-e3,3\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.33      0.12         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.67      0.70      0.68        23\n",
      "           4       0.73      0.67      0.70        12\n",
      "           5       0.73      0.62      0.67        13\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.44      0.46      0.43        60\n",
      "weighted avg       0.56      0.55      0.55        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 4  0  4  1  0]\n",
      " [ 5  0 16  0  2]\n",
      " [ 1  0  2  8  1]\n",
      " [ 3  0  0  2  8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-e4,1\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.67      0.36         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.68      0.91      0.78        23\n",
      "           4       0.80      0.67      0.73        12\n",
      "           5       0.82      0.69      0.75        13\n",
      "\n",
      "    accuracy                           0.67        60\n",
      "   macro avg       0.51      0.59      0.52        60\n",
      "weighted avg       0.61      0.67      0.62        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  7  0  0]\n",
      " [ 0  0 21  1  1]\n",
      " [ 1  0  2  8  1]\n",
      " [ 3  0  0  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-e4,2\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      1.00      0.35         3\n",
      "           2       0.17      0.11      0.13         9\n",
      "           3       0.67      0.61      0.64        23\n",
      "           4       1.00      0.58      0.74        12\n",
      "           5       0.83      0.77      0.80        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.58      0.61      0.53        60\n",
      "weighted avg       0.67      0.58      0.60        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 4  1  4  0  0]\n",
      " [ 4  4 14  0  1]\n",
      " [ 2  0  2  7  1]\n",
      " [ 1  1  1  0 10]]\n"
     ]
    }
   ],
   "source": [
    "#SVM-e4,3\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.33      0.14         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.71      0.74      0.72        23\n",
      "           4       0.70      0.58      0.64        12\n",
      "           5       0.60      0.69      0.64        13\n",
      "\n",
      "    accuracy                           0.57        60\n",
      "   macro avg       0.42      0.47      0.43        60\n",
      "weighted avg       0.55      0.57      0.55        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 6  0  3  0  0]\n",
      " [ 0  0 17  2  4]\n",
      " [ 1  0  2  7  2]\n",
      " [ 3  0  0  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#nn-e1\n",
    "\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(20,30,50,70,5), random_state=42)\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36666666666666664\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.18      0.67      0.29         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.56      0.43      0.49        23\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.37      0.77      0.50        13\n",
      "\n",
      "    accuracy                           0.37        60\n",
      "   macro avg       0.22      0.37      0.25        60\n",
      "weighted avg       0.30      0.37      0.31        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 3  0  4  0  2]\n",
      " [ 4  4 10  0  5]\n",
      " [ 1  0  1  0 10]\n",
      " [ 1  0  2  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#nn-e2\n",
    "\n",
    "\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(20,30,50,70,5), random_state=42)\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4166666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.33      0.25         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.50      0.39      0.44        23\n",
      "           4       0.27      0.33      0.30        12\n",
      "           5       0.58      0.85      0.69        13\n",
      "\n",
      "    accuracy                           0.42        60\n",
      "   macro avg       0.31      0.38      0.33        60\n",
      "weighted avg       0.38      0.42      0.39        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  1  1  0  0]\n",
      " [ 1  0  4  3  1]\n",
      " [ 3  2  9  6  3]\n",
      " [ 0  0  4  4  4]\n",
      " [ 0  0  0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#nn-e3\n",
    "\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(20,30,50,70,5), random_state=42)\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4166666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.15      0.22      0.18         9\n",
      "           3       0.59      0.57      0.58        23\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.40      0.77      0.53        13\n",
      "\n",
      "    accuracy                           0.42        60\n",
      "   macro avg       0.23      0.31      0.26        60\n",
      "weighted avg       0.34      0.42      0.36        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1  0  1]\n",
      " [ 0  2  4  0  3]\n",
      " [ 0  5 13  0  5]\n",
      " [ 0  2  4  0  6]\n",
      " [ 0  3  0  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#nn-e4\n",
    "\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(20,30,50,70,5), random_state=42)\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
