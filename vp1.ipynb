{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required necessary libraries are installed pandas numpai sea Bond matplot live and few others algorithm library algorithms from sk learn our installed\n",
    "The collected data from the Google form is converted into CSV commerce operated values and it is loaded to a data frame and named it named as DF \n",
    "In the initial process of cleaning the data the date and time of collections are dropped and and the most irrelevant column with most and nan values is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             area_of_improvement recommdation_likeliness  \\\n",
      "0              Campus facilities                  Likely   \n",
      "1  Communication and information                  Likely   \n",
      "2       Student support services                 Neutral   \n",
      "3              Campus facilities             Very likely   \n",
      "4       Student support services           Very unlikely   \n",
      "\n",
      "  communication_availability online_platform extracurricular_activities  \\\n",
      "0                    Average         Average                       Good   \n",
      "1                  Excellent       Excellent                       Good   \n",
      "2                    Average         Average                    Average   \n",
      "3                    Average            Good                       Good   \n",
      "4                  Excellent       Excellent                       Poor   \n",
      "\n",
      "  library_availibility prompt_feedback  classroom_interaction  course_clarity  \\\n",
      "0              Average             Yes                      5               4   \n",
      "1            Excellent              No                      4               4   \n",
      "2              Average              No                      3               3   \n",
      "3                 Good             Yes                      5               3   \n",
      "4        Below Average              No                      3               3   \n",
      "\n",
      "  student_support_services     academic_advisers    cleanliness  \\\n",
      "0                       No  Moderately Available  Below Average   \n",
      "1                      Yes  Moderately Available      Excellent   \n",
      "2                       No  Moderately Available        Average   \n",
      "3                      Yes  Moderately Available           Good   \n",
      "4                       No  Moderately Available           Good   \n",
      "\n",
      "  research_resources          accommodation course_curriculum  \\\n",
      "0             Average  Moderately satisfied              Good   \n",
      "1           Excellent        Very satisfied         Excellent   \n",
      "2             Average  Moderately satisfied           Average   \n",
      "3                Good        Very satisfied              Good   \n",
      "4           Excellent         Not satisfied     Below Average   \n",
      "\n",
      "  teaching_quality  student_satisfaction  \n",
      "0             Good                     4  \n",
      "1          Average                     4  \n",
      "2          Average                     3  \n",
      "3          Average                     4  \n",
      "4          Average                     2  \n",
      "Index(['area_of_improvement', 'recommdation_likeliness',\n",
      "       'communication_availability', 'online_platform',\n",
      "       'extracurricular_activities', 'library_availibility', 'prompt_feedback',\n",
      "       'classroom_interaction', 'course_clarity', 'student_support_services',\n",
      "       'academic_advisers', 'cleanliness', 'research_resources ',\n",
      "       'accommodation', 'course_curriculum', 'teaching_quality',\n",
      "       'student_satisfaction'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   area_of_improvement         299 non-null    object\n",
      " 1   recommdation_likeliness     299 non-null    object\n",
      " 2   communication_availability  299 non-null    object\n",
      " 3   online_platform             299 non-null    object\n",
      " 4   extracurricular_activities  299 non-null    object\n",
      " 5   library_availibility        299 non-null    object\n",
      " 6   prompt_feedback             299 non-null    object\n",
      " 7   classroom_interaction       299 non-null    int64 \n",
      " 8   course_clarity              299 non-null    int64 \n",
      " 9   student_support_services    299 non-null    object\n",
      " 10  academic_advisers           299 non-null    object\n",
      " 11  cleanliness                 299 non-null    object\n",
      " 12  research_resources          299 non-null    object\n",
      " 13  accommodation               299 non-null    object\n",
      " 14  course_curriculum           299 non-null    object\n",
      " 15  teaching_quality            299 non-null    object\n",
      " 16  student_satisfaction        299 non-null    int64 \n",
      "dtypes: int64(3), object(14)\n",
      "memory usage: 39.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('vp1.csv',encoding='latin-1')\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean    3.361204\n",
      "50%     3.000000\n",
      "std     1.286207\n",
      "Name: student_satisfaction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#descriptive analysis\n",
    "\n",
    "# Calculate mean, median, and standard deviation for student_satisfaction\n",
    "descriptive_stats = df['student_satisfaction'].describe()\n",
    "# Extract mean, median, and standard deviation into a separate DataFrame\n",
    "stats_df = descriptive_stats.loc[['mean', '50%', 'std']]\n",
    "\n",
    "# Print the descriptive statistics\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptive analysis is done after prepressing where based on students satisfaction score given by students mean median and standard deviations are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#visualization\n",
    "\n",
    "# Calculate statistics for student_satisfaction\n",
    "average_rating = df['student_satisfaction'].mean()\n",
    "std_dev = df['student_satisfaction'].std()\n",
    "median_value = df['student_satisfaction'].median()\n",
    "\n",
    "# Create a bar chart with multiple bars for average rating, standard deviation, and mode\n",
    "plt.bar(['Average Rating', 'Standard Deviation', 'Median'], [average_rating, std_dev, median_value])\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Statistics for Student Satisfaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the visualization for the same thing is done using a bar chart with multiple bars for average rating standard deviation and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area_of_improvement', 'recommdation_likeliness',\n",
      "       'communication_availability', 'online_platform',\n",
      "       'extracurricular_activities', 'library_availibility', 'prompt_feedback',\n",
      "       'classroom_interaction', 'course_clarity', 'student_support_services',\n",
      "       'academic_advisers', 'cleanliness', 'research_resources ',\n",
      "       'accommodation', 'course_curriculum', 'teaching_quality',\n",
      "       'student_satisfaction'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation analysis done for students satisfaction and two important categories of the collected data course clarity and teaching quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      3\n",
      "1      2\n",
      "2      2\n",
      "3      2\n",
      "4      2\n",
      "      ..\n",
      "294    4\n",
      "295    3\n",
      "296    4\n",
      "297    1\n",
      "298    3\n",
      "Name: teaching_quality, Length: 299, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['recommdation_likeliness'] = df['recommdation_likeliness'].map({\n",
    "    'Very unlikely': 0,\n",
    "    'Unlikely': 1,\n",
    "    'Neutral': 2,\n",
    "    'Likely': 3,\n",
    "    'Very likely': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['communication_availability'] = df['communication_availability'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['online_platform'] = df['online_platform'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['library_availibility'] = df['library_availibility'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['prompt_feedback'] = df['prompt_feedback'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "    \n",
    "})\n",
    "\n",
    "df['student_support_services'] = df['student_support_services'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "})\n",
    "\n",
    "df['academic_advisers'] = df['academic_advisers'].map({\n",
    "    'Not Available': 0,\n",
    "    'Slightly Available': 1,\n",
    "    'Moderately Available': 2,\n",
    "    'Very Available': 3\n",
    "   \n",
    "})\n",
    "\n",
    "df['cleanliness'] = df['cleanliness'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['research_resources '] = df['research_resources '].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['accommodation'] = df['accommodation'].map({\n",
    "    'Not satisfied': 0,\n",
    "    'Slightly satisfied': 1,\n",
    "    'Moderately satisfied': 2,\n",
    "    'Very satisfied': 3,\n",
    "    'Extremely satisfied': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['course_curriculum'] = df['course_curriculum'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "\n",
    "df['teaching_quality'] = df['teaching_quality'].map({\n",
    "    'Poor': 0,\n",
    "    'Below Average': 1,\n",
    "    'Average': 2,\n",
    "    'Good': 3,\n",
    "    'Excellent': 4,\n",
    "   \n",
    "})\n",
    "print(df['teaching_quality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommdation_likeliness</th>\n",
       "      <th>communication_availability</th>\n",
       "      <th>online_platform</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>library_availibility</th>\n",
       "      <th>prompt_feedback</th>\n",
       "      <th>classroom_interaction</th>\n",
       "      <th>course_clarity</th>\n",
       "      <th>student_support_services</th>\n",
       "      <th>academic_advisers</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>research_resources</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>course_curriculum</th>\n",
       "      <th>teaching_quality</th>\n",
       "      <th>student_satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.742475</td>\n",
       "      <td>2.67893</td>\n",
       "      <td>2.712375</td>\n",
       "      <td>2.612040</td>\n",
       "      <td>2.722408</td>\n",
       "      <td>0.729097</td>\n",
       "      <td>3.438127</td>\n",
       "      <td>3.364548</td>\n",
       "      <td>0.525084</td>\n",
       "      <td>1.979933</td>\n",
       "      <td>2.742475</td>\n",
       "      <td>2.752508</td>\n",
       "      <td>2.357860</td>\n",
       "      <td>2.899666</td>\n",
       "      <td>2.963211</td>\n",
       "      <td>3.361204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.088640</td>\n",
       "      <td>1.14572</td>\n",
       "      <td>1.194597</td>\n",
       "      <td>1.278365</td>\n",
       "      <td>1.310720</td>\n",
       "      <td>0.445171</td>\n",
       "      <td>1.302560</td>\n",
       "      <td>1.317492</td>\n",
       "      <td>0.500208</td>\n",
       "      <td>0.982873</td>\n",
       "      <td>1.286443</td>\n",
       "      <td>1.080153</td>\n",
       "      <td>1.232541</td>\n",
       "      <td>0.967578</td>\n",
       "      <td>0.924309</td>\n",
       "      <td>1.286207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recommdation_likeliness  communication_availability  online_platform  \\\n",
       "count               299.000000                   299.00000       299.000000   \n",
       "mean                  2.742475                     2.67893         2.712375   \n",
       "std                   1.088640                     1.14572         1.194597   \n",
       "min                   0.000000                     0.00000         0.000000   \n",
       "25%                   2.000000                     2.00000         2.000000   \n",
       "50%                   3.000000                     3.00000         3.000000   \n",
       "75%                   4.000000                     4.00000         4.000000   \n",
       "max                   4.000000                     4.00000         4.000000   \n",
       "\n",
       "       extracurricular_activities  library_availibility  prompt_feedback  \\\n",
       "count                  299.000000            299.000000       299.000000   \n",
       "mean                     2.612040              2.722408         0.729097   \n",
       "std                      1.278365              1.310720         0.445171   \n",
       "min                      0.000000              0.000000         0.000000   \n",
       "25%                      2.000000              2.000000         0.000000   \n",
       "50%                      3.000000              3.000000         1.000000   \n",
       "75%                      4.000000              4.000000         1.000000   \n",
       "max                      4.000000              4.000000         1.000000   \n",
       "\n",
       "       classroom_interaction  course_clarity  student_support_services  \\\n",
       "count             299.000000      299.000000                299.000000   \n",
       "mean                3.438127        3.364548                  0.525084   \n",
       "std                 1.302560        1.317492                  0.500208   \n",
       "min                 1.000000        1.000000                  0.000000   \n",
       "25%                 3.000000        3.000000                  0.000000   \n",
       "50%                 4.000000        3.000000                  1.000000   \n",
       "75%                 5.000000        4.000000                  1.000000   \n",
       "max                 5.000000        5.000000                  1.000000   \n",
       "\n",
       "       academic_advisers  cleanliness  research_resources   accommodation  \\\n",
       "count         299.000000   299.000000           299.000000     299.000000   \n",
       "mean            1.979933     2.742475             2.752508       2.357860   \n",
       "std             0.982873     1.286443             1.080153       1.232541   \n",
       "min             0.000000     0.000000             0.000000       0.000000   \n",
       "25%             1.000000     2.000000             2.000000       2.000000   \n",
       "50%             2.000000     3.000000             3.000000       2.000000   \n",
       "75%             3.000000     4.000000             3.500000       3.000000   \n",
       "max             3.000000     4.000000             4.000000       4.000000   \n",
       "\n",
       "       course_curriculum  teaching_quality  student_satisfaction  \n",
       "count         299.000000        299.000000            299.000000  \n",
       "mean            2.899666          2.963211              3.361204  \n",
       "std             0.967578          0.924309              1.286207  \n",
       "min             0.000000          0.000000              1.000000  \n",
       "25%             3.000000          3.000000              3.000000  \n",
       "50%             3.000000          3.000000              3.000000  \n",
       "75%             4.000000          4.000000              4.000000  \n",
       "max             4.000000          4.000000              5.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         student_satisfaction  recommdation_likeliness\n",
      "student_satisfaction                 1.000000                 0.447708\n",
      "recommdation_likeliness              0.447708                 1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'recommdation_likeliness']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            student_satisfaction  communication_availability\n",
      "student_satisfaction                    1.000000                    0.443308\n",
      "communication_availability              0.443308                    1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'communication_availability']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  online_platform\n",
      "student_satisfaction              1.000000         0.340842\n",
      "online_platform                   0.340842         1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'online_platform']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            student_satisfaction  extracurricular_activities\n",
      "student_satisfaction                    1.000000                    0.434503\n",
      "extracurricular_activities              0.434503                    1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'extracurricular_activities']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  library_availibility\n",
      "student_satisfaction              1.000000              0.423937\n",
      "library_availibility              0.423937              1.000000\n"
     ]
    }
   ],
   "source": [
    "##corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'library_availibility']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  prompt_feedback\n",
      "student_satisfaction              1.000000         0.271099\n",
      "prompt_feedback                   0.271099         1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','prompt_feedback']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       student_satisfaction  classroom_interaction\n",
      "student_satisfaction               1.000000               0.620285\n",
      "classroom_interaction              0.620285               1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','classroom_interaction']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  course_clarity\n",
      "student_satisfaction              1.000000        0.591366\n",
      "course_clarity                    0.591366        1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','course_clarity']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          student_satisfaction  student_support_services\n",
      "student_satisfaction                  1.000000                  0.178856\n",
      "student_support_services              0.178856                  1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','student_support_services']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  academic_advisers\n",
      "student_satisfaction              1.000000           0.417193\n",
      "academic_advisers                 0.417193           1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','academic_advisers']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  cleanliness\n",
      "student_satisfaction              1.000000     0.421458\n",
      "cleanliness                       0.421458     1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','cleanliness']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  research_resources \n",
      "student_satisfaction              1.000000             0.424455\n",
      "research_resources                0.424455             1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction','research_resources ']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  accommodation\n",
      "student_satisfaction              1.000000       0.447379\n",
      "accommodation                     0.447379       1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'accommodation']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  course_curriculum\n",
      "student_satisfaction               1.00000            0.40402\n",
      "course_curriculum                  0.40402            1.00000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction',  'course_curriculum']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      student_satisfaction  teaching_quality\n",
      "student_satisfaction              1.000000          0.423321\n",
      "teaching_quality                  0.423321          1.000000\n"
     ]
    }
   ],
   "source": [
    "#corelation analysis\n",
    "\n",
    "\n",
    "attributes = ['student_satisfaction', 'teaching_quality']\n",
    "\n",
    "# Create a subset DataFrame with the selected attributes\n",
    "subset_df = df[attributes]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a box plot to visualize the relationship between 'recommdation_likeliness' and 'student_satisfaction'\n",
    "sns.boxplot(x='recommdation_likeliness', y='student_satisfaction', data=df)\n",
    "plt.xlabel('recommdation_likeliness')\n",
    "plt.ylabel('student_satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a box plot to visualize the relationship between 'communication_availability' and 'student_satisfaction'\n",
    "sns.boxplot(x='communication_availability', y='student_satisfaction', data=df)\n",
    "plt.xlabel('communication_availability')\n",
    "plt.ylabel('student_satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "# Jittering the data points\n",
    "jitter_x = np.random.uniform(-0.2, 0.2, len(df))\n",
    "jitter_y = np.random.uniform(-0.1, 0.1, len(df))\n",
    "\n",
    "# Scatter plot with jitter\n",
    "plt.scatter(df['online_platform'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Online Platform')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Online Platform vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Avg', 'Avg', 'Good', 'Excellent'])  # Set custom x-axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with jitter\n",
    "plt.scatter(df['extracurricular_activities'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('extracurricular_activities')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('extracurricular_activities vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Avg', 'Avg', 'Good', 'Excellent'])  # Set custom x-axis labels\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot with jitter\n",
    "plt.scatter(df['library_availibility'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('library_availibility')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('library_availibility vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Avg', 'Avg', 'Good', 'Excellent'])  # Set custom x-axis labels\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot with jittered data points-------------------------------------------------okayish\n",
    "plt.scatter(df['prompt_feedback'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Prompt Feedback')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Prompt Feedback vs Student Satisfaction')\n",
    "plt.xticks([0, 1], ['No', 'Yes'])  # Set custom x-axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below thing is not included in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the average student satisfaction for each category of 'Prompt Feedback'-------------------------not apt\n",
    "# avg_satisfaction = df.groupby('prompt_feedback')['student_satisfaction'].mean()\n",
    "\n",
    "# # Create a grouped bar chart\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.barplot(x=avg_satisfaction.index, y=avg_satisfaction.values, palette='muted')\n",
    "# plt.xlabel('Prompt Feedback')\n",
    "# plt.ylabel('Average Student Satisfaction')\n",
    "# plt.title('Average Student Satisfaction by Prompt Feedback')\n",
    "# plt.xticks([0, 1], ['No', 'Yes'])  # Set custom x-axis labels\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate the average student satisfaction for each category of 'sudent_support_services'----------------------not apt\n",
    "# avg_satisfaction = df.groupby('student_support_services')['student_satisfaction'].mean()\n",
    "\n",
    "# # Create a grouped bar chart\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.barplot(x=avg_satisfaction.index, y=avg_satisfaction.values, palette='muted')\n",
    "# plt.xlabel('student_support_services')\n",
    "# plt.ylabel('Average Student Satisfaction')\n",
    "# plt.title('Average Student Satisfaction by student_support_services')\n",
    "# plt.xticks([0, 1], ['No', 'Yes'])  # Set custom x-axis labels\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Box plot for 'prompt_feedback' against 'student_satisfaction'\n",
    "# sns.boxplot(x='prompt_feedback', y='student_satisfaction', data=df)\n",
    "# plt.xlabel('Prompt Feedback')\n",
    "# plt.ylabel('Student Satisfaction')\n",
    "# plt.title('Box Plot: Prompt Feedback vs Student Satisfaction')\n",
    "# plt.xticks([0, 1], ['No', 'Yes'])  # Set custom x-axis labels\n",
    "# plt.show()\n",
    "\n",
    "# #not much to infer from these two\n",
    "\n",
    "# # Box plot for 'student_support_services' against 'student_satisfaction'\n",
    "# sns.boxplot(x='student_support_services', y='student_satisfaction', data=df)\n",
    "# plt.xlabel('student_support_services')\n",
    "# plt.ylabel('Student Satisfaction')\n",
    "# plt.title('Box Plot: student_support_services vs Student Satisfaction')\n",
    "# plt.xticks([0, 1], ['No', 'Yes'])  # Set custom x-axis labels\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a density plot for 'academic_advisers' against 'student_satisfaction'\n",
    "sns.kdeplot(data=df, x='academic_advisers', hue='student_satisfaction', fill=True)\n",
    "plt.xlabel('Academic Advisers Availability')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot: Academic Advisers Availability vs Student Satisfaction')\n",
    "plt.legend(title='Student Satisfaction', labels=['Not Satisfied', 'Satisfied', 'Neutral', 'Likely'])\n",
    "plt.xticks([0, 1, 2, 3], ['Not Available', 'Slightly Available', 'Moderately Available', 'Very Available'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 5, 2, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['course_clarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the data\n",
    "sns.kdeplot(data=df, x='course_clarity', hue='student_satisfaction', fill=True)\n",
    "plt.xlabel('Course Clarity')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot: Course Clarity vs Student Satisfaction')\n",
    "plt.legend(title='Student Satisfaction', labels=['Not Satisfied', 'Satisfied', 'Neutral', 'Likely'])\n",
    "plt.xticks([1, 2, 3, 4, 5], ['Very Unclear', 'Unclear', 'Neutral', 'Clear', 'Very Clear'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 3, 1, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['research_resources '].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the data\n",
    "sns.kdeplot(data=df, x='research_resources ', hue='student_satisfaction', fill=True)\n",
    "plt.xlabel('Research Resources Availibility')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot: Research Resources vs Student Satisfaction')\n",
    "plt.legend(title='Student Satisfaction', labels=['Not Satisfied', 'Satisfied', 'Neutral', 'Likely'])\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Not Available  ', 'Slightly ', 'Moderately ', 'Very', 'Extremely'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for 'cleanliness' against 'student_satisfaction'\n",
    "plt.scatter(df['cleanliness'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Cleanliness')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Cleanliness vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for 'research_resources ' against 'student_satisfaction'\n",
    "plt.scatter(df['research_resources '] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Research Resources')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Research Resources vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Scatter plot for 'accommodation' against 'student_satisfaction'----when in confusion what to infer use boxplot\n",
    "plt.scatter(df['accommodation'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Accommodation')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Accommodation vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Not satisfied', 'Slightly satisfied', 'Moderately satisfied', 'Very satisfied', 'Extremely satisfied'])\n",
    "plt.show()\n",
    "\n",
    "# Box plot for 'accommodation' against 'student_satisfaction'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='accommodation', y='student_satisfaction', data=df, palette='Set1')\n",
    "plt.xlabel('Accommodation')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Accommodation vs Student Satisfaction (Box Plot)')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Not satisfied', 'Slightly satisfied', 'Moderately satisfied', 'Very satisfied', 'Extremely satisfied'])\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for 'course_curriculum' against 'student_satisfaction'----when in confusion what to infer use boxplot\n",
    "plt.scatter(df['course_curriculum'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Course Curriculum')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Course Curriculum vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "# Box plot for 'course_curriculum' against 'student_satisfaction'\n",
    "sns.boxplot(data=df, x='course_curriculum', y='student_satisfaction', palette='Set1')\n",
    "plt.xlabel('Course Curriculum')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Course Curriculum vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for 'teaching_quality' against 'student_satisfaction'----when in confusion what to infer use boxplot\n",
    "plt.scatter(df['teaching_quality'] + jitter_x, df['student_satisfaction'] + jitter_y, alpha=0.5)\n",
    "plt.xlabel('Teaching Quality')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Teaching Quality vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Box plot for 'teaching_quality' against 'student_satisfaction'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='teaching_quality', y='student_satisfaction', data=df, palette='pastel')\n",
    "plt.xlabel('Teaching Quality')\n",
    "plt.ylabel('Student Satisfaction')\n",
    "plt.title('Teaching Quality vs Student Satisfaction')\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Poor', 'Below Average', 'Average', 'Good', 'Excellent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_attributes = ['recommdation_likeliness', 'communication_availability',\n",
    "              'online_platform', 'extracurricular_activities', 'library_availibility',\n",
    "              'prompt_feedback', 'classroom_interaction', 'course_clarity',\n",
    "              'student_support_services', 'academic_advisers', 'cleanliness',\n",
    "              'research_resources ', 'accommodation', 'course_curriculum',\n",
    "              'teaching_quality']\n",
    "\n",
    "\n",
    "\n",
    "# # Create a DataFrame to store the mean student satisfaction for each attribute\n",
    "# summary_df = df[summary_attributes].drop('student_satisfaction', axis=1).apply(lambda col: df.groupby(col)['student_satisfaction'].mean()).T\n",
    "\n",
    "# # Calculate the overall mean student satisfaction for reference\n",
    "# overall_mean_satisfaction = df['student_satisfaction'].mean()\n",
    "\n",
    "# # Categorize the attributes as \"Satisfied\" or \"Needs Improvement\" based on mean satisfaction\n",
    "# summary_df['Category'] = summary_df.apply(lambda row: 'Satisfied' if row.mean() >= overall_mean_satisfaction else 'Needs Improvement', axis=1)\n",
    "\n",
    "# # Sort the DataFrame based on the mean student satisfaction score in descending order\n",
    "# summary_df = summary_df.sort_values(by='Category', ascending=False)\n",
    "\n",
    "# # Print the summary\n",
    "# print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #decision tree------not used\n",
    "# summary_attributes = ['recommdation_likeliness', 'communication_availability',\n",
    "#               'online_platform', 'extracurricular_activities', 'library_availibility',\n",
    "#               'prompt_feedback', 'classroom_interaction', 'course_clarity',\n",
    "#               'student_support_services', 'academic_advisers', 'cleanliness',\n",
    "#               'research_resources ', 'accommodation', 'course_curriculum',\n",
    "#               'teaching_quality','student_satisfaction']\n",
    "\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X = df[summary_attributes].drop('student_satisfaction', axis=1)\n",
    "# y = df['student_satisfaction']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize the Decision Tree Classifier\n",
    "# dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test data\n",
    "# y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4666666666666667\n",
      "Accuracy: 0.4666666666666667\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 5  1  3  0  0]\n",
      " [ 1  2 14  6  0]\n",
      " [ 2  0  6  4  0]\n",
      " [ 3  1  0  2  7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.67      0.25         3\n",
      "           2       0.25      0.11      0.15         9\n",
      "           3       0.58      0.61      0.60        23\n",
      "           4       0.33      0.33      0.33        12\n",
      "           5       1.00      0.54      0.70        13\n",
      "\n",
      "    accuracy                           0.47        60\n",
      "   macro avg       0.46      0.45      0.41        60\n",
      "weighted avg       0.55      0.47      0.48        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "\n",
    "academic_attributes = ['student_satisfaction','recommdation_likeliness',\n",
    "'course_clarity',\n",
    "'research_resources ',\n",
    "'course_curriculum',\n",
    "'teaching_quality']\n",
    "academic_df = df[academic_attributes]\n",
    "# One-hot encode the categorical variables\n",
    "academic_df_encoded = pd.get_dummies(academic_df, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = academic_df_encoded.drop('student_satisfaction', axis=1)\n",
    "y = academic_df_encoded['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5166666666666667\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  7  0  0]\n",
      " [ 2  3 12  5  1]\n",
      " [ 0  0  3  7  2]\n",
      " [ 1  0  2  0 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.67      0.40         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.48      0.52      0.50        23\n",
      "           4       0.58      0.58      0.58        12\n",
      "           5       0.77      0.77      0.77        13\n",
      "\n",
      "    accuracy                           0.52        60\n",
      "   macro avg       0.42      0.51      0.45        60\n",
      "weighted avg       0.48      0.52      0.49        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/n5mjk3bs7tjc_2kc5wbk_ft00000gn/T/ipykernel_8432/3785578698.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  support_df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "support_attributes = ['prompt_feedback',\n",
    "'classroom_interaction',\n",
    "'student_support_services',\n",
    "'academic_advisers',\n",
    "'student_satisfaction']\n",
    "\n",
    "# Create a subset DataFrame with the support attributes and the target variable 'student_satisfaction'\n",
    "support_df = df[support_attributes]\n",
    "\n",
    "# Drop rows with any missing values\n",
    "support_df.dropna(inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = support_df.drop('student_satisfaction', axis=1)\n",
    "y = support_df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48333333333333334\n",
      "Confusion Matrix:\n",
      "[[1 0 1 0 1]\n",
      " [1 3 5 0 0]\n",
      " [1 6 9 2 5]\n",
      " [2 0 3 7 0]\n",
      " [0 1 0 3 9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.33      0.25         3\n",
      "           2       0.30      0.33      0.32         9\n",
      "           3       0.50      0.39      0.44        23\n",
      "           4       0.58      0.58      0.58        12\n",
      "           5       0.60      0.69      0.64        13\n",
      "\n",
      "    accuracy                           0.48        60\n",
      "   macro avg       0.44      0.47      0.45        60\n",
      "weighted avg       0.49      0.48      0.48        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/n5mjk3bs7tjc_2kc5wbk_ft00000gn/T/ipykernel_8432/740540724.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  facilty_df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "facilty_attributes = ['student_satisfaction',\n",
    "'communication_availability',\n",
    "'online_platform',\n",
    "'extracurricular_activities',\n",
    "'library_availibility',\n",
    "'accommodation',\n",
    "'cleanliness']\n",
    "# Create a subset DataFrame with the facility attributes and the target variable 'student_satisfaction'\n",
    "facilty_df = df[facilty_attributes]\n",
    "\n",
    "# Drop rows with any missing values\n",
    "facilty_df.dropna(inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = facilty_df.drop('student_satisfaction', axis=1)\n",
    "y =facilty_df['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 1  2  6  0  0]\n",
      " [ 4  2 15  0  2]\n",
      " [ 0  2  1  6  3]\n",
      " [ 0  0  0  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.33      0.22      0.27         9\n",
      "           3       0.68      0.65      0.67        23\n",
      "           4       1.00      0.50      0.67        12\n",
      "           5       0.72      1.00      0.84        13\n",
      "\n",
      "    accuracy                           0.65        60\n",
      "   macro avg       0.62      0.67      0.60        60\n",
      "weighted avg       0.69      0.65      0.64        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree with feature eng- cat1-equal weights\n",
    "academic_attributes = ['student_satisfaction','recommdation_likeliness','course_clarity','research_resources ','course_curriculum','prompt_feedback','teaching_quality']\n",
    "df['academic_interaction'] = df[academic_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 1\n",
    "weights_category1 = [0.1,0.1, 0.1, 0.1, 0.1, 0.1,0.1]  \n",
    "df['academic_weighted_score'] = (df[academic_attributes] * weights_category1).sum(axis=1)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df[['academic_weighted_score','academic_interaction']]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree with academic_weighted_score\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6333333333333333\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 2  4  3  0  0]\n",
      " [ 1  4 13  4  1]\n",
      " [ 0  1  3  7  1]\n",
      " [ 0  0  2  0 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67         3\n",
      "           2       0.44      0.44      0.44         9\n",
      "           3       0.62      0.57      0.59        23\n",
      "           4       0.64      0.58      0.61        12\n",
      "           5       0.85      0.85      0.85        13\n",
      "\n",
      "    accuracy                           0.63        60\n",
      "   macro avg       0.61      0.69      0.63        60\n",
      "weighted avg       0.64      0.63      0.63        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree with feature eng- cat1-chosen weights\n",
    "academic_attributes = ['student_satisfaction','recommdation_likeliness','course_clarity','research_resources ','course_curriculum','prompt_feedback','teaching_quality']\n",
    "\n",
    "df['academic_interaction'] = df[academic_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 1\n",
    "weights_category1 = [0.1, 0.1, 0.3, 0.2, 0.2,0.1,0.3] \n",
    "df['academic_weighted_score'] = (df[academic_attributes] * weights_category1).sum(axis=1)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df[['academic_weighted_score','academic_interaction']]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree with academic_weighted_score\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #decision tree with feature eng- weighted cat1----not used\n",
    "# academic_attributes = ['student_satisfaction','recommdation_likeliness','course_clarity','research_resources ','course_curriculum','prompt_feedback','teaching_quality']\n",
    "\n",
    "# # Weighted score for Category 1\n",
    "\n",
    "# weights_category1 = [0.1, 0.2, 0.3, 0.2, 0.2,0.1,0.3]\n",
    "# df['academic_weighted_score'] = (df[academic_attributes] * weights_category1).sum(axis=1)\n",
    "\n",
    "# # Split the data into features (X) and target (y)\n",
    "# X = df[['academic_weighted_score']]\n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Decision Tree with academic_weighted_score\n",
    "# dt = DecisionTreeClassifier(random_state=42)\n",
    "# dt.fit(X_train, y_train)\n",
    "# y_pred = dt.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# # Calculate and display the confusion matrix\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "\n",
    "# # Display the classification report\n",
    "# class_report = classification_report(y_test, y_pred)\n",
    "# print(\"Classification Report:\")\n",
    "# print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 2  0 16  3  2]\n",
      " [ 0  0  3  7  2]\n",
      " [ 1  0  2  0 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.67      0.44         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.53      0.70      0.60        23\n",
      "           4       0.70      0.58      0.64        12\n",
      "           5       0.71      0.77      0.74        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.46      0.54      0.49        60\n",
      "weighted avg       0.52      0.58      0.54        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#decision tree with feature eng- cat2- assigned weights\n",
    "\n",
    "support_attributes = ['prompt_feedback', 'classroom_interaction', 'student_support_services', 'academic_advisers']\n",
    "\n",
    "\n",
    "# Interaction for Category 2\n",
    "df['support_interaction'] = df[support_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 2\n",
    "weights_category2 = [0.1, 0.2, 0.3, 0.1]  \n",
    "df['support_weighted_score'] = (df[support_attributes] * weights_category2).sum(axis=1)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df[['support_interaction','support_weighted_score']]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree with academic_weighted_score\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5166666666666667\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 0  0  6  3  0]\n",
      " [ 2  0 14  6  1]\n",
      " [ 0  0  2  9  1]\n",
      " [ 0  0  1  5  7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.33      0.33         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.56      0.61      0.58        23\n",
      "           4       0.39      0.75      0.51        12\n",
      "           5       0.78      0.54      0.64        13\n",
      "\n",
      "    accuracy                           0.52        60\n",
      "   macro avg       0.41      0.45      0.41        60\n",
      "weighted avg       0.48      0.52      0.48        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#decision tree with feature eng- cat2-equal weights\n",
    "support_attributes = ['prompt_feedback', 'classroom_interaction', 'student_support_services', 'academic_advisers']\n",
    "\n",
    "# Interaction for Category 2\n",
    "df['support_interaction'] = df[support_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 2\n",
    "weights_category2 = [0.1, 0.1, 0.1, 0.1]  \n",
    "df['support_weighted_score'] = (df[support_attributes] * weights_category2).sum(axis=1)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df[['support_weighted_score','support_weighted_score']]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree with academic_weighted_score\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 1  0  2  4  2]\n",
      " [ 2  2 14  4  1]\n",
      " [ 1  0  4  3  4]\n",
      " [ 0  0  1  3  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.33      0.25         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.61      0.61      0.61        23\n",
      "           4       0.21      0.25      0.23        12\n",
      "           5       0.56      0.69      0.62        13\n",
      "\n",
      "    accuracy                           0.45        60\n",
      "   macro avg       0.32      0.38      0.34        60\n",
      "weighted avg       0.41      0.45      0.43        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree with feature eng- cat3-equal weights\n",
    "facility_attributes = ['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']\n",
    "\n",
    "# Interaction for Category 3\n",
    "df['facility_interaction'] = df[facility_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 3\n",
    "weights_category3 = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]  \n",
    "df['facility_weighted_score'] = (df[facility_attributes] * weights_category3).sum(axis=1)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df[['facility_interaction','facility_weighted_score']]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree with academic_weighted_score\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Confusion Matrix:\n",
      "[[2 0 1 0 0]\n",
      " [2 1 1 3 2]\n",
      " [5 4 9 3 2]\n",
      " [2 0 3 4 3]\n",
      " [2 0 1 2 8]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.67      0.25         3\n",
      "           2       0.20      0.11      0.14         9\n",
      "           3       0.60      0.39      0.47        23\n",
      "           4       0.33      0.33      0.33        12\n",
      "           5       0.53      0.62      0.57        13\n",
      "\n",
      "    accuracy                           0.40        60\n",
      "   macro avg       0.36      0.42      0.35        60\n",
      "weighted avg       0.45      0.40      0.41        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree with feature eng- cat3-assigned weights\n",
    "facility_attributes = ['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']\n",
    "\n",
    "# Interaction for Category 3\n",
    "df['facility_interaction'] = df[facility_attributes].prod(axis=1)\n",
    "\n",
    "# Weighted score for Category 3\n",
    "weights_category3 = [0.1, 0.2, 0.1, 0.2, 0.2, 0.1] \n",
    "df['facility_weighted_score'] = (df[facility_attributes] * weights_category3).sum(axis=1)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df[['facility_weighted_score','facility_interaction']]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree with academic_weighted_score\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #KNN---------didnt use\n",
    "# X = df[['recommdation_likeliness', 'course_clarity', 'research_resources ', 'course_curriculum', 'teaching_quality']]  \n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create and train the KNN model\n",
    "# knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict 'student_satisfaction' on the testing set\n",
    "# y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area_of_improvement', 'recommdation_likeliness',\n",
      "       'communication_availability', 'online_platform',\n",
      "       'extracurricular_activities', 'library_availibility', 'prompt_feedback',\n",
      "       'classroom_interaction', 'course_clarity', 'student_support_services',\n",
      "       'academic_advisers', 'cleanliness', 'research_resources ',\n",
      "       'accommodation', 'course_curriculum', 'teaching_quality',\n",
      "       'student_satisfaction', 'academic_interaction',\n",
      "       'academic_weighted_score', 'support_interaction',\n",
      "       'support_weighted_score', 'facility_interaction',\n",
      "       'facility_weighted_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df['academic_interaction'] = df[academic_attributes].prod(axis=1)\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #KNN\n",
    "# X = df[['academic_weighted_score']] \n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create and train the KNN model\n",
    "# knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict 'student_satisfaction' on the testing set\n",
    "# y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #KNN\n",
    "# X = df[['prompt_feedback', 'classroom_interaction', 'student_support_services', 'academic_advisers']]  \n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create and train the KNN model\n",
    "# knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict 'student_satisfaction' on the testing set\n",
    "# y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #KNN\n",
    "# X = df[['support_weighted_score']]  \n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create and train the KNN model\n",
    "# knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict 'student_satisfaction' on the testing set\n",
    "# y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #KNN\n",
    "# X = df[['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']]  \n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create and train the KNN model\n",
    "# knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict 'student_satisfaction' on the testing set\n",
    "# y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #KNN\n",
    "# X = df[['facility_weighted_score']]  \n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# # Create and train the KNN model\n",
    "# knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict 'student_satisfaction' on the testing set\n",
    "# y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6846666666666665\n"
     ]
    }
   ],
   "source": [
    "#KNN-----exp2\n",
    "\n",
    "X = df[['extracurricular_activities','library_availibility','student_support_services','accommodation','cleanliness','online_platform']]  \n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict 'student_satisfaction' on the testing set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so far the lowest when online and extra things were given more importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.602\n"
     ]
    }
   ],
   "source": [
    "#KNN---exp1\n",
    "# Assuming X contains the features and y contains the 'student_satisfaction'\n",
    "X = df[['academic_interaction',\n",
    "       'academic_weighted_score', 'support_interaction',\n",
    "       'support_weighted_score', 'facility_interaction',\n",
    "       'facility_weighted_score']]  \n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict 'student_satisfaction' on the testing set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6213333333333332\n"
     ]
    }
   ],
   "source": [
    "#KNN--exp3\n",
    "X = df[['teaching_quality','online_platform','research_resources ',\n",
    "    'course_curriculum','academic_advisers','library_availibility',\n",
    "    'extracurricular_activities','student_support_services']]  \n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict 'student_satisfaction' on the testing set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of lowest when they studied online,took councelling,extra curricular and studied themselves?m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df.drop(df.columns[17:24], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   area_of_improvement         299 non-null    object\n",
      " 1   recommdation_likeliness     299 non-null    int64 \n",
      " 2   communication_availability  299 non-null    int64 \n",
      " 3   online_platform             299 non-null    int64 \n",
      " 4   extracurricular_activities  299 non-null    int64 \n",
      " 5   library_availibility        299 non-null    int64 \n",
      " 6   prompt_feedback             299 non-null    int64 \n",
      " 7   classroom_interaction       299 non-null    int64 \n",
      " 8   course_clarity              299 non-null    int64 \n",
      " 9   student_support_services    299 non-null    int64 \n",
      " 10  academic_advisers           299 non-null    int64 \n",
      " 11  cleanliness                 299 non-null    int64 \n",
      " 12  research_resources          299 non-null    int64 \n",
      " 13  accommodation               299 non-null    int64 \n",
      " 14  course_curriculum           299 non-null    int64 \n",
      " 15  teaching_quality            299 non-null    int64 \n",
      " 16  student_satisfaction        299 non-null    int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 39.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38333333333333336\n",
      "Confusion Matrix:\n",
      "[[ 0  0  3  0  0]\n",
      " [ 0  0  7  2  0]\n",
      " [ 0  0 20  3  0]\n",
      " [ 0  0  9  3  0]\n",
      " [ 1  0  8  4  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.43      0.87      0.57        23\n",
      "           4       0.25      0.25      0.25        12\n",
      "           5       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.38        60\n",
      "   macro avg       0.14      0.22      0.16        60\n",
      "weighted avg       0.21      0.38      0.27        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB-e1,1\n",
    "academic_attributes = ['recommdation_likeliness', 'course_clarity', 'research_resources ', 'course_curriculum', 'teaching_quality']\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "\n",
    "X = academic_df_encoded.drop('student_satisfaction', axis=1)\n",
    "y = academic_df_encoded['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5666666666666667\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  7  0  0]\n",
      " [ 2  0 16  3  2]\n",
      " [ 0  0  3  6  3]\n",
      " [ 1  0  1  1 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.67      0.40         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.57      0.70      0.63        23\n",
      "           4       0.60      0.50      0.55        12\n",
      "           5       0.67      0.77      0.71        13\n",
      "\n",
      "    accuracy                           0.57        60\n",
      "   macro avg       0.42      0.53      0.46        60\n",
      "weighted avg       0.50      0.57      0.52        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB GAUSS-e1,2\n",
    "\n",
    "academic_attributes = ['recommdation_likeliness', 'course_clarity', 'research_resources ', 'course_curriculum', 'teaching_quality']\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = academic_df_encoded.drop('student_satisfaction', axis=1)\n",
    "y = academic_df_encoded['student_satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3\n",
      "Confusion Matrix:\n",
      "[[ 0  0  2  0  1]\n",
      " [ 0  0  5  3  1]\n",
      " [ 0  0 14  7  2]\n",
      " [ 0  0  9  3  0]\n",
      " [ 0  0 12  0  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.33      0.61      0.43        23\n",
      "           4       0.23      0.25      0.24        12\n",
      "           5       0.20      0.08      0.11        13\n",
      "\n",
      "    accuracy                           0.30        60\n",
      "   macro avg       0.15      0.19      0.16        60\n",
      "weighted avg       0.22      0.30      0.24        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB-e3,1\n",
    "facility_attributes = ['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5166666666666667\n",
      "Confusion Matrix:\n",
      "[[ 1  1  0  1  0]\n",
      " [ 1  0  4  1  3]\n",
      " [ 0  2 12  6  3]\n",
      " [ 0  0  3  5  4]\n",
      " [ 0  0  0  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.33      0.40         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.63      0.52      0.57        23\n",
      "           4       0.38      0.42      0.40        12\n",
      "           5       0.57      1.00      0.72        13\n",
      "\n",
      "    accuracy                           0.52        60\n",
      "   macro avg       0.42      0.45      0.42        60\n",
      "weighted avg       0.47      0.52      0.48        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NB-e3,2\n",
    "facility_attributes = ['communication_availability', 'online_platform', 'extracurricular_activities', 'library_availibility', 'accommodation', 'cleanliness']\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 0  0 23  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 1  0 12  0  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.33      0.33         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.40      1.00      0.57        23\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.40        60\n",
      "   macro avg       0.15      0.27      0.18        60\n",
      "weighted avg       0.17      0.40      0.24        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB-support attributes-e2,1\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  4  1  2]\n",
      " [ 4  0 12  5  2]\n",
      " [ 0  0  2  6  4]\n",
      " [ 1  0  2  0 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.67      0.33         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.57      0.52      0.55        23\n",
      "           4       0.50      0.50      0.50        12\n",
      "           5       0.56      0.77      0.65        13\n",
      "\n",
      "    accuracy                           0.50        60\n",
      "   macro avg       0.37      0.49      0.40        60\n",
      "weighted avg       0.45      0.50      0.47        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB-support attributes-e2,2\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 5  1  3  0  0]\n",
      " [ 1  2 14  6  0]\n",
      " [ 1  0  4  7  0]\n",
      " [ 3  1  0  1  8]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      1.00      0.38         3\n",
      "           2       0.25      0.11      0.15         9\n",
      "           3       0.67      0.61      0.64        23\n",
      "           4       0.50      0.58      0.54        12\n",
      "           5       1.00      0.62      0.76        13\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.53      0.58      0.49        60\n",
      "weighted avg       0.62      0.55      0.56        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST-e1\n",
    "\n",
    "\n",
    "academic_attributes = ['recommdation_likeliness', 'course_clarity', 'research_resources ', 'course_curriculum', 'teaching_quality']\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = academic_df_encoded.drop('student_satisfaction', axis=1)\n",
    "y = academic_df_encoded['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 1  3 13  5  1]\n",
      " [ 0  0  2  8  2]\n",
      " [ 1  0  0  2 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.67      0.50         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.54      0.57      0.55        23\n",
      "           4       0.53      0.67      0.59        12\n",
      "           5       0.77      0.77      0.77        13\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.45      0.53      0.48        60\n",
      "weighted avg       0.50      0.55      0.52        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST-e2\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Confusion Matrix:\n",
      "[[ 1  1  1  0  0]\n",
      " [ 2  2  5  0  0]\n",
      " [ 0  1 13  5  4]\n",
      " [ 2  0  7  2  1]\n",
      " [ 0  0  0  4  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.33      0.25         3\n",
      "           2       0.50      0.22      0.31         9\n",
      "           3       0.50      0.57      0.53        23\n",
      "           4       0.18      0.17      0.17        12\n",
      "           5       0.64      0.69      0.67        13\n",
      "\n",
      "    accuracy                           0.45        60\n",
      "   macro avg       0.40      0.40      0.39        60\n",
      "weighted avg       0.45      0.45      0.44        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST-e3\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6833333333333333\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 2  0  7  0  0]\n",
      " [ 0  0 20  2  1]\n",
      " [ 1  0  3  8  0]\n",
      " [ 3  0  0  0 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      1.00      0.50         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.67      0.87      0.75        23\n",
      "           4       0.80      0.67      0.73        12\n",
      "           5       0.91      0.77      0.83        13\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.54      0.66      0.56        60\n",
      "weighted avg       0.63      0.68      0.64        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST-e4\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "highest of all models-random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6166666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      1.00      0.43         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.74      0.87      0.80        23\n",
      "           4       0.62      0.42      0.50        12\n",
      "           5       0.64      0.69      0.67        13\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.46      0.60      0.48        60\n",
      "weighted avg       0.56      0.62      0.57        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 5  0  3  1  0]\n",
      " [ 0  0 20  1  2]\n",
      " [ 1  0  3  5  3]\n",
      " [ 2  0  1  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#LOGREG-e1\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "logreg_classifier = LogisticRegression()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.67      0.36         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.59      0.70      0.64        23\n",
      "           4       0.57      0.33      0.42        12\n",
      "           5       0.56      0.77      0.65        13\n",
      "\n",
      "    accuracy                           0.53        60\n",
      "   macro avg       0.39      0.49      0.41        60\n",
      "weighted avg       0.47      0.53      0.49        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  5  2  0]\n",
      " [ 3  0 16  1  3]\n",
      " [ 0  0  3  4  5]\n",
      " [ 1  0  2  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#LOGREG-e2\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "logreg_classifier = LogisticRegression()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43333333333333335\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.56      0.43      0.49        23\n",
      "           4       0.28      0.42      0.33        12\n",
      "           5       0.58      0.85      0.69        13\n",
      "\n",
      "    accuracy                           0.43        60\n",
      "   macro avg       0.28      0.34      0.30        60\n",
      "weighted avg       0.39      0.43      0.40        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1  1  0]\n",
      " [ 1  0  4  2  2]\n",
      " [ 2  1 10  8  2]\n",
      " [ 0  0  3  5  4]\n",
      " [ 0  0  0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#LOGREG-e3\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "logreg_classifier = LogisticRegression()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48333333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.67      0.27         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.57      0.52      0.55        23\n",
      "           4       0.55      0.50      0.52        12\n",
      "           5       0.64      0.69      0.67        13\n",
      "\n",
      "    accuracy                           0.48        60\n",
      "   macro avg       0.39      0.48      0.40        60\n",
      "weighted avg       0.48      0.48      0.47        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 4  0  4  1  0]\n",
      " [ 4  2 12  3  2]\n",
      " [ 1  0  2  6  3]\n",
      " [ 1  0  2  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/n5mjk3bs7tjc_2kc5wbk_ft00000gn/T/ipykernel_8432/703141520.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['student_support_services'] = X['student_support_services'].map({\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#LOGREG-e4\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assuming 'X' is the DataFrame containing the attributes for training and 'y' is the target variable\n",
    "\n",
    "# Drop unwanted columns\n",
    "X = df[summary_attributes]\n",
    "\n",
    "# Map categorical attributes to numerical representations\n",
    "X['student_support_services'] = X['student_support_services'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "})\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "logreg_classifier = LogisticRegression()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second highest of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #62-LOGREG-------not used\n",
    "# # Split the data into features (X) and the target variable (y)\n",
    "# X = df[[ 'teaching_quality','online_platform','research_resources ','course_curriculum','academic_advisers','library_availibility', 'extracurricular_activities','student_support_services']]\n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a Logistic Regression classifier\n",
    "# logreg_classifier = LogisticRegression()\n",
    "\n",
    "# # Train the classifier on the training data\n",
    "# logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Print the confusion matrix\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #69-LOGREG----no\n",
    "# X = df[['extracurricular_activities','library_availibility','student_support_services','accommodation', 'cleanliness','accommodation','online_platform']]  \n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a Logistic Regression classifier\n",
    "# logreg_classifier = LogisticRegression()\n",
    "\n",
    "# # Train the classifier on the training data\n",
    "# logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Print the confusion matrix\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      1.00      0.35         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.90      0.78      0.84        23\n",
      "           4       0.60      0.75      0.67        12\n",
      "           5       0.73      0.62      0.67        13\n",
      "\n",
      "    accuracy                           0.63        60\n",
      "   macro avg       0.49      0.63      0.50        60\n",
      "weighted avg       0.63      0.63      0.62        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 7  0  1  1  0]\n",
      " [ 0  0 18  3  2]\n",
      " [ 1  0  1  9  1]\n",
      " [ 3  0  0  2  8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-LINEAR-e1,1\n",
    "\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier  \n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.67      0.36         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.64      0.78      0.71        23\n",
      "           4       0.50      0.50      0.50        12\n",
      "           5       0.75      0.69      0.72        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.43      0.53      0.46        60\n",
      "weighted avg       0.52      0.58      0.54        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  6  1  0]\n",
      " [ 1  0 18  4  0]\n",
      " [ 1  0  2  6  3]\n",
      " [ 2  0  1  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-RBF-e1,2\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.13      0.67      0.22         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.68      0.65      0.67        23\n",
      "           4       0.54      0.58      0.56        12\n",
      "           5       0.90      0.69      0.78        13\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.45      0.52      0.45        60\n",
      "weighted avg       0.57      0.55      0.55        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 7  0  2  0  0]\n",
      " [ 2  0 15  6  0]\n",
      " [ 1  0  3  7  1]\n",
      " [ 3  0  1  0  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-POLY-e1,3\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48333333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.13      0.67      0.22         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.65      0.57      0.60        23\n",
      "           4       0.57      0.33      0.42        12\n",
      "           5       0.56      0.77      0.65        13\n",
      "\n",
      "    accuracy                           0.48        60\n",
      "   macro avg       0.38      0.47      0.38        60\n",
      "weighted avg       0.49      0.48      0.47        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 3  0  4  2  0]\n",
      " [ 6  0 13  1  3]\n",
      " [ 1  0  2  4  5]\n",
      " [ 3  0  0  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-LINEAR-e2,1\n",
    "\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier  \n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.67      0.50         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.55      0.74      0.63        23\n",
      "           4       0.67      0.50      0.57        12\n",
      "           5       0.67      0.77      0.71        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.46      0.54      0.48        60\n",
      "weighted avg       0.51      0.58      0.54        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 1  0 17  3  2]\n",
      " [ 0  0  3  6  3]\n",
      " [ 1  0  2  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-RBF-e2,2\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.33      0.33         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.56      0.83      0.67        23\n",
      "           4       0.71      0.42      0.53        12\n",
      "           5       0.62      0.77      0.69        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.45      0.47      0.44        60\n",
      "weighted avg       0.51      0.58      0.53        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 1  0  8  0  0]\n",
      " [ 0  0 19  2  2]\n",
      " [ 0  0  3  5  4]\n",
      " [ 1  0  2  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-POLY-e2,3\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.58      0.61      0.60        23\n",
      "           4       0.37      0.58      0.45        12\n",
      "           5       0.65      0.85      0.73        13\n",
      "\n",
      "    accuracy                           0.53        60\n",
      "   macro avg       0.32      0.41      0.36        60\n",
      "weighted avg       0.44      0.53      0.48        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  2  1  0]\n",
      " [ 0  0  5  2  2]\n",
      " [ 0  0 14  7  2]\n",
      " [ 0  0  3  7  2]\n",
      " [ 0  0  0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-LINEAR-e3,1\n",
    "\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier  \n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF-MORE ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.33      0.40         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.63      0.74      0.68        23\n",
      "           4       0.38      0.50      0.43        12\n",
      "           5       0.73      0.85      0.79        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.45      0.48      0.46        60\n",
      "weighted avg       0.50      0.58      0.54        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  0  1  1  0]\n",
      " [ 1  0  5  2  1]\n",
      " [ 0  0 17  5  1]\n",
      " [ 0  0  4  6  2]\n",
      " [ 0  0  0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-RBF-e3,2\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.59      0.70      0.64        23\n",
      "           4       0.28      0.42      0.33        12\n",
      "           5       0.75      0.69      0.72        13\n",
      "\n",
      "    accuracy                           0.50        60\n",
      "   macro avg       0.32      0.36      0.34        60\n",
      "weighted avg       0.45      0.50      0.47        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  2  0]\n",
      " [ 0  0  5  4  0]\n",
      " [ 2  0 16  4  1]\n",
      " [ 0  0  5  5  2]\n",
      " [ 1  0  0  3  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-POLY-e3,3\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.33      0.12         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.67      0.70      0.68        23\n",
      "           4       0.73      0.67      0.70        12\n",
      "           5       0.73      0.62      0.67        13\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.44      0.46      0.43        60\n",
      "weighted avg       0.56      0.55      0.55        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 4  0  4  1  0]\n",
      " [ 5  0 16  0  2]\n",
      " [ 1  0  2  8  1]\n",
      " [ 3  0  0  2  8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-e4,1\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wowwwwwwwwww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.67      0.36         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.68      0.91      0.78        23\n",
      "           4       0.80      0.67      0.73        12\n",
      "           5       0.82      0.69      0.75        13\n",
      "\n",
      "    accuracy                           0.67        60\n",
      "   macro avg       0.51      0.59      0.52        60\n",
      "weighted avg       0.61      0.67      0.62        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 2  0  7  0  0]\n",
      " [ 0  0 21  1  1]\n",
      " [ 1  0  2  8  1]\n",
      " [ 3  0  0  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM-e4,2\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      1.00      0.35         3\n",
      "           2       0.17      0.11      0.13         9\n",
      "           3       0.67      0.61      0.64        23\n",
      "           4       1.00      0.58      0.74        12\n",
      "           5       0.83      0.77      0.80        13\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.58      0.61      0.53        60\n",
      "weighted avg       0.67      0.58      0.60        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0]\n",
      " [ 4  1  4  0  0]\n",
      " [ 4  4 14  0  1]\n",
      " [ 2  0  2  7  1]\n",
      " [ 1  1  1  0 10]]\n"
     ]
    }
   ],
   "source": [
    "#SVM-e4,3\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.33      0.14         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.71      0.74      0.72        23\n",
      "           4       0.70      0.58      0.64        12\n",
      "           5       0.60      0.69      0.64        13\n",
      "\n",
      "    accuracy                           0.57        60\n",
      "   macro avg       0.42      0.47      0.43        60\n",
      "weighted avg       0.55      0.57      0.55        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  0  2  0  0]\n",
      " [ 6  0  3  0  0]\n",
      " [ 0  0 17  2  4]\n",
      " [ 1  0  2  7  2]\n",
      " [ 3  0  0  1  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#nn-e1\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[academic_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the neural network classifier\n",
    "\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(20,30,50,70,5), random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #nn-----no\n",
    "# # Define the attributes for the neural network\n",
    "# nn_attributes = ['online_platform','research_resources ','course_curriculum','library_availibility','academic_advisers','library_availibility']\n",
    "\n",
    "# # Separate the features (attributes) and target variable\n",
    "# X = df[nn_attributes]\n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets (80% training, 20% testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize the neural network classifier\n",
    "# #\n",
    "# # Feel free to experiment with the number of layers and neurons to find the best configuration for your data.\n",
    "# nn_classifier = MLPClassifier(hidden_layer_sizes=(50,50,50), random_state=42)\n",
    "\n",
    "# # Train the classifier on the training data\n",
    "# nn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36666666666666664\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.18      0.67      0.29         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.56      0.43      0.49        23\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.37      0.77      0.50        13\n",
      "\n",
      "    accuracy                           0.37        60\n",
      "   macro avg       0.22      0.37      0.25        60\n",
      "weighted avg       0.30      0.37      0.31        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  0]\n",
      " [ 3  0  4  0  2]\n",
      " [ 4  4 10  0  5]\n",
      " [ 1  0  1  0 10]\n",
      " [ 1  0  2  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#nn-e2\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[support_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the neural network classifier\n",
    "# Here, we create a neural network with 2 hidden layers, each containing 100 neurons.\n",
    "# Feel free to experiment with the number of layers and neurons to find the best configuration for your data.\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(20,30,50,70,5), random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4166666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.33      0.25         3\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.50      0.39      0.44        23\n",
      "           4       0.27      0.33      0.30        12\n",
      "           5       0.58      0.85      0.69        13\n",
      "\n",
      "    accuracy                           0.42        60\n",
      "   macro avg       0.31      0.38      0.33        60\n",
      "weighted avg       0.38      0.42      0.39        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  1  1  0  0]\n",
      " [ 1  0  4  3  1]\n",
      " [ 3  2  9  6  3]\n",
      " [ 0  0  4  4  4]\n",
      " [ 0  0  0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#nn-e3\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[facility_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the neural network classifier\n",
    "# Here, we create a neural network with 2 hidden layers, each containing 100 neurons.\n",
    "# Feel free to experiment with the number of layers and neurons to find the best configuration for your data.\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(20,30,50,70,5), random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4166666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.15      0.22      0.18         9\n",
      "           3       0.59      0.57      0.58        23\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.40      0.77      0.53        13\n",
      "\n",
      "    accuracy                           0.42        60\n",
      "   macro avg       0.23      0.31      0.26        60\n",
      "weighted avg       0.34      0.42      0.36        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1  0  1]\n",
      " [ 0  2  4  0  3]\n",
      " [ 0  5 13  0  5]\n",
      " [ 0  2  4  0  6]\n",
      " [ 0  3  0  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vaishnavimurthys/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#nn-e4\n",
    "\n",
    "# Separate the features (attributes) and target variable\n",
    "X = df[summary_attributes]\n",
    "y = df['student_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the neural network classifier\n",
    "# Here, we create a neural network with 2 hidden layers, each containing 100 neurons.\n",
    "# Feel free to experiment with the number of layers and neurons to find the best configuration for your data.\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(20,30,50,70,5), random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #whatttttt?\n",
    "# # Separate the features (attributes) and target variable\n",
    "# X = df[academic_attributes]\n",
    "# y = df['student_satisfaction']\n",
    "\n",
    "# # Split the data into training and testing sets (80% training, 20% testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Standardize the feature data (optional but can help improve convergence)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Define the parameter grid for hyperparameter tuning\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(50, 50), (100, 100), (50, 100)],\n",
    "#     'alpha': [0.001, 0.01, 0.1],\n",
    "#     'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "# }\n",
    "\n",
    "# # Initialize the neural network classifier\n",
    "# nn_classifier = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "# # Initialize GridSearchCV to find the best hyperparameters\n",
    "# grid_search = GridSearchCV(nn_classifier, param_grid, cv=5)\n",
    "\n",
    "# # Train the classifier on the training data with hyperparameter tuning\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Get the best hyperparameters found by GridSearchCV\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# # Initialize the neural network classifier with the best hyperparameters\n",
    "# nn_classifier = MLPClassifier(max_iter=1000, **best_params, random_state=42)\n",
    "\n",
    "# # Train the classifier on the training data\n",
    "# nn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = nn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
